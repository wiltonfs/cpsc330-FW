{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](../img/330-banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Lecture 7: Linear Models\n",
    "------------\n",
    "\n",
    "UBC 2022-23 W2\n",
    "\n",
    "Instructor: Amir Abdi\n",
    " - Office Hours: Mondays 5-6 (or 5-7 if student turn-out was high)\n",
    "\n",
    "<br><br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please share your Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img_aa/qr-code-feedback-Amir.png\" height=\"300\" width=\"300\"> \n",
    "\n",
    "https://forms.gle/NLKCe3BrLC6tLpkE8\n",
    "\n",
    "It's 100% **anonymous**\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Announcements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Homework 3 is due Feb 1, 11:59pm. \n",
    "- Homework 4 will be posted soon.\n",
    "- Midterm is coming up: Feb 15 Wednesday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Learning outcomes\n",
    "\n",
    "From this lecture, students are expected to be able to: \n",
    "\n",
    "- Explain the **general intuition** behind **linear models**;\n",
    "- Explain how `predict` works for linear regression;\n",
    "- Use `scikit-learn`'s `Ridge` model; \n",
    "- Demonstrate how the `alpha` hyperparameter of `Ridge` is related to the fundamental tradeoff; \n",
    "- Explain the difference between linear regression and logistic regression;   \n",
    "- Use `scikit-learn`'s `LogisticRegression` model and `predict_proba` to get probability scores\n",
    "- Explain the advantages of getting probability scores instead of hard predictions during classification; \n",
    "- Broadly describe linear SVMs \n",
    "- Explain how can you interpret model predictions using coefficients learned by a linear model; \n",
    "- Explain the advantages and limitations of linear classifiers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legends\n",
    "\n",
    "    \n",
    "| <img src=\"https://upload.wikimedia.org/wikipedia/commons/f/f8/This_is_the_photo_of_Arthur_Samuel.jpg\" width=\"100\"> | <img src=\"http://www.cs.cmu.edu/~tom/TomHead2-6-22-22.jpg\" width=\"100\">  | <img src=\"https://upload.wikimedia.org/wikipedia/commons/4/49/John_McCarthy_Stanford.jpg\" width=\"100\"> | <img src=\"https://datascience.columbia.edu/wp-content/uploads/2020/08/Vapnik_web.png\" width=\"100\"> | <img src=\"https://upload.wikimedia.org/wikipedia/commons/a/a1/Alan_Turing_Aged_16.jpg\" width=\"100\">\n",
    "| :-----------: | :-----------: | :-----------: | :-----------: | :-----------: |\n",
    "| Arthur Samuel       | Tom Mitchell       |John McCarthy|  Vladimir N. Vapnik | Alan Turing |\n",
    "| (1901-1990)    | 1951 - Now       |  1927 – 2011 | 1936 - Now | 1912 – 1954 |\n",
    "| First computer learning program | 1997 ML Texbook, CMU Prof | Co-coined term AI, Lisp,<br> Time-sharing, Garbage collection | SVM | Turing Test, Turning Machine\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear models [[video](https://youtu.be/HXd1U2q4VFA)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Linear models** is a fundamental and widely used class of models. They are called **linear** because they make a prediction using a **linear function** of the input features.  \n",
    "\n",
    "We will talk about three linear models: \n",
    "- Linear regression \n",
    "- Logistic regression\n",
    "- Linear SVM (brief mention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear regression \n",
    "\n",
    "- A very popular statistical model and has a long history.  \n",
    "- Imagine a hypothetical regression problem of predicting weight of a snake given its length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../code/.\")\n",
    "\n",
    "import IPython\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "#import mglearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "from ipywidgets import interact, interactive\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a dataset with a **linear equation** (e.g. `y = 5 * x + 0.2`) plus some added **random noise**.\n",
    "\n",
    "For example: \n",
    "- X = Length of the snake\n",
    "- y = weight of the snake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1.489130</td>\n",
       "      <td>10.507995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.073233</td>\n",
       "      <td>7.658047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1.622709</td>\n",
       "      <td>9.748797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.984653</td>\n",
       "      <td>9.731572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.484937</td>\n",
       "      <td>3.016555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      length     weight\n",
       "73  1.489130  10.507995\n",
       "53  1.073233   7.658047\n",
       "80  1.622709   9.748797\n",
       "49  0.984653   9.731572\n",
       "23  0.484937   3.016555"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "n = 100\n",
    "X_1 = np.linspace(0, 2, n) + np.random.randn(n) * 0.01\n",
    "X = pd.DataFrame(X_1[:, None], columns=[\"length\"])\n",
    "\n",
    "y = abs(np.random.randn(n, 1)) * 3 + X_1[:, None] * 5 + 0.2\n",
    "y = pd.DataFrame(y, columns=[\"weight\"])\n",
    "snakes_df = pd.concat([X, y], axis=1)\n",
    "train_df, test_df = train_test_split(snakes_df, test_size=0.2, random_state=77)\n",
    "\n",
    "X_train = train_df[[\"length\"]].values\n",
    "y_train = train_df[\"weight\"].values\n",
    "X_test = test_df[[\"length\"]].values\n",
    "y_test = test_df[\"weight\"].values\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's visualize the hypothetical snake data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_train, y_train, \".\", markersize=10)\n",
    "plt.xlabel(\"length\")\n",
    "plt.ylabel(\"weight (target)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's plot a **linear regression** model on this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.linspace(min(X_train)[0], max(X_train)[0], 1000)\n",
    "grid = grid.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# ----------- New Code ------------\n",
    "r = Ridge()\n",
    "r.fit(X_train, y_train)\n",
    "# ----------- New Code ------------\n",
    "\n",
    "plt.plot(X_train, y_train, \".\", markersize=10)\n",
    "plt.plot(grid, r.predict(grid))\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"length\")\n",
    "plt.ylabel(\"weight (target)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The orange line is the learned linear model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Prediction of linear regression\n",
    "\n",
    "- Given a snake length, we can use the model above to predict the target (i.e., the weight of the snake). \n",
    "- The prediction will be the corresponding weight on the orange line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.20683258])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snake_length = 0.75\n",
    "r.predict([[snake_length]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### What are we exactly learning? \n",
    "\n",
    "- The model above is a **line**, which can be represented with a slope (i.e., coefficient or weight) and an intercept. \n",
    "- For the above model, we can access the slope (i.e., coefficient or weight) and the intercept using `coef_` and `intercept_`, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.26370005])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.coef_  # r is our linear regression object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2590575478171857"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.intercept_  # r is our linear regression object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# redraw the plot\n",
    "plt.plot(X_train, y_train, \".\", markersize=10)\n",
    "plt.plot(grid, r.predict(grid))\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"length\")\n",
    "plt.ylabel(\"weight (target)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How are we making predictions? \n",
    "- Given a feature value $x_1$ and learned coefficient $w_1$ and intercept $b$, we can get the prediction $\\hat{y}$ with the following formula:\n",
    "$$\\hat{y} = w_1x_1 + b$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "snake_length = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.20683258])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.predict([[snake_length]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.20683258])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snake_length * r.coef_ + r.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we exactly know how the model is making the prediction. \n",
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generalizing to more features\n",
    "For more features, the model is a higher dimensional hyperplane and the general prediction formula looks as follows: \n",
    "\n",
    "$\\hat{y} =$ <font color=\"red\">$w_1$</font> <font color=\"blue\">$x_1$ </font> $+ \\dots +$ <font color=\"red\">$w_d$</font> <font color=\"blue\">$x_d$</font> + <font  color=\"green\"> $b$</font>\n",
    "\n",
    "where, \n",
    "- <font  color=\"blue\"> ($x_1, \\dots, x_d$) are input features </font>\n",
    "- <font  color=\"red\"> ($w_1, \\dots, w_d$) are coefficients or weights </font> (**learned** from the data)\n",
    "- <font  color=\"green\"> $b$ is the bias which can be used to offset your hyperplane </font> (**learned** from the data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: How many **learned** parameters does the following Linear model has?\n",
    "\n",
    "$\\hat{y} = w_1 x_1 + w_2 x_2 + b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer = ???\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Example \n",
    "\n",
    "- Suppose these are the coefficients learned by a linear regression model on a hypothetical housing price prediction dataset. \n",
    "\n",
    "| Feature | Learned coefficient |\n",
    "|--------------------|---------------------:|\n",
    "| Bedrooms | 0.20 |\n",
    "| Bathrooms| 0.11 |\n",
    "| Square Footage | 0.002 |\n",
    "| Age | -0.02 |\n",
    "\n",
    "- Now given a new example, the target will be predicted as follows: \n",
    "| Bedrooms | Bathrooms | Square Footage | Age |\n",
    "|--------------------|---------------------|----------------|-----| \n",
    "| 3                  | 2                   | 1875           | 66  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{y} = w_1x_1 + w_2x_2 + w_3x_3 + w_4x_4 + b$$\n",
    "\n",
    "$$\\text{predicted price}=  0.20 \\times 3 + 0.11 \\times 2 + 0.002 \\times 1875 + (-0.02) \\times 66 + b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "When we call `fit`, a **coefficient (or weight)** is learned for each feature which tells us the role of that feature in prediction.  \n",
    "These **coefficients** are learned from the training data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br><br>\n",
    "In linear models for regression, the model is \n",
    "- a line for a single feature, \n",
    "- a plane for two features, and \n",
    "- a hyperplane for higher dimensions. \n",
    "\n",
    "We are not yet ready to discuss how does linear regression learn these coefficients and intercept.\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `scikit-learn` has a model called `LinearRegression` for linear regression. \n",
    "    - But if we use this **\"no regularization\"** version of linear regression, it may result in large coefficients and unexpected results. \n",
    "    - **Objective Function:** $||y - Xw||^2_2$\n",
    "- We use a linear regression model with **$l2$ regularization** called `Ridge Regression`\n",
    "  - hyperparameter: `alpha`\n",
    "  - **Objective Function:**  $||y - Xw||^2_2 + alpha * ||w||^2_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "**Regularization** controls the fundamental bias/variance tradeoff.\n",
    "\n",
    "**More regularization** -> more bias -> less variance --> less complex model --> **less chance of overfitting**\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `Ridge` Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression  # Linear Regression without any regularization\n",
    "from sklearn.linear_model import Ridge  # Linear Regression with l2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sample Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `sklearn`'s built in regression dataset, the **Boston Housing dataset**. The task associated with this dataset is to predict the median value of homes in several Boston neighborhoods in the 1970s, using information such as crime rate in the neighbourhood, average number of rooms, proximity to the Charles River, highway accessibility, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0000</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.303030</td>\n",
       "      <td>1.082251</td>\n",
       "      <td>725.0</td>\n",
       "      <td>3.138528</td>\n",
       "      <td>38.03</td>\n",
       "      <td>-121.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0000</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.506410</td>\n",
       "      <td>1.134615</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>3.288462</td>\n",
       "      <td>34.00</td>\n",
       "      <td>-118.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0474</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.419355</td>\n",
       "      <td>1.006452</td>\n",
       "      <td>858.0</td>\n",
       "      <td>2.767742</td>\n",
       "      <td>37.31</td>\n",
       "      <td>-121.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.2794</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.546473</td>\n",
       "      <td>1.044166</td>\n",
       "      <td>5146.0</td>\n",
       "      <td>3.392221</td>\n",
       "      <td>34.46</td>\n",
       "      <td>-117.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.5551</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.018487</td>\n",
       "      <td>1.016807</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>3.169748</td>\n",
       "      <td>37.35</td>\n",
       "      <td>-121.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16507</th>\n",
       "      <td>3.0185</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.205479</td>\n",
       "      <td>0.863014</td>\n",
       "      <td>434.0</td>\n",
       "      <td>1.981735</td>\n",
       "      <td>34.61</td>\n",
       "      <td>-120.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16508</th>\n",
       "      <td>12.6320</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.462963</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>208.0</td>\n",
       "      <td>3.851852</td>\n",
       "      <td>34.44</td>\n",
       "      <td>-119.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16509</th>\n",
       "      <td>3.9808</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.678689</td>\n",
       "      <td>1.006557</td>\n",
       "      <td>999.0</td>\n",
       "      <td>3.275410</td>\n",
       "      <td>38.28</td>\n",
       "      <td>-121.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16510</th>\n",
       "      <td>5.8195</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.585513</td>\n",
       "      <td>0.961771</td>\n",
       "      <td>1645.0</td>\n",
       "      <td>3.309859</td>\n",
       "      <td>33.71</td>\n",
       "      <td>-117.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16511</th>\n",
       "      <td>3.7315</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.368304</td>\n",
       "      <td>1.738839</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>2.421875</td>\n",
       "      <td>37.58</td>\n",
       "      <td>-118.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16512 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0       2.0000      52.0  5.303030   1.082251       725.0  3.138528     38.03   \n",
       "1       2.0000      52.0  5.506410   1.134615      1026.0  3.288462     34.00   \n",
       "2       4.0474      30.0  5.419355   1.006452       858.0  2.767742     37.31   \n",
       "3       3.2794       7.0  5.546473   1.044166      5146.0  3.392221     34.46   \n",
       "4       2.5551      35.0  4.018487   1.016807      1886.0  3.169748     37.35   \n",
       "...        ...       ...       ...        ...         ...       ...       ...   \n",
       "16507   3.0185      17.0  4.205479   0.863014       434.0  1.981735     34.61   \n",
       "16508  12.6320       5.0  7.462963   0.888889       208.0  3.851852     34.44   \n",
       "16509   3.9808      20.0  5.678689   1.006557       999.0  3.275410     38.28   \n",
       "16510   5.8195      25.0  6.585513   0.961771      1645.0  3.309859     33.71   \n",
       "16511   3.7315      20.0  7.368304   1.738839      1085.0  2.421875     37.58   \n",
       "\n",
       "       Longitude  \n",
       "0        -121.88  \n",
       "1        -118.30  \n",
       "2        -121.94  \n",
       "3        -117.20  \n",
       "4        -121.86  \n",
       "...          ...  \n",
       "16507    -120.16  \n",
       "16508    -119.31  \n",
       "16509    -121.20  \n",
       "16510    -117.97  \n",
       "16511    -118.74  \n",
       "\n",
       "[16512 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "california = fetch_california_housing()\n",
    "\n",
    "# Create test and train data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    california.data, california.target, test_size=0.2\n",
    ")\n",
    "pd.DataFrame(X_train, columns=california.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block group\n",
      "        - HouseAge      median house age in block group\n",
      "        - AveRooms      average number of rooms per household\n",
      "        - AveBedrms     average number of bedrooms per household\n",
      "        - Population    block group population\n",
      "        - AveOccup      average number of household members\n",
      "        - Latitude      block group latitude\n",
      "        - Longitude     block group longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "An household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surpinsingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(california.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Ridge` on the California housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.6051017968063611\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(StandardScaler(), Ridge())\n",
    "scores = cross_validate(pipe, X_train, y_train, return_train_score=True)\n",
    "print('validation score:', pd.DataFrame(scores)['test_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hyperparameter `alpha` of `Ridge`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ridge has hyperparameters just like the rest of the models we learned.\n",
    "- The alpha hyperparameter is what makes `Ridge` different from vanilla `LinearRegression`. \n",
    "- Similar to the other hyperparameters that we saw, `alpha` controls the fundamental tradeoff. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "-----------\n",
    "\n",
    "If we set `alpha=0` of **Ridge Regression**, it is the same as using LinearRegression.\n",
    "\n",
    "\n",
    "Linear Regresion: \n",
    "- $||y - Xw||^2_2\n",
    "\n",
    "Ridge Regression (Linear Regression with $l2$ regularization): \n",
    "- $||y - Xw||^2_2 + alpha * ||w||^2_2$\n",
    "-----------\n",
    "<br><br><br><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's examine the effect of `alpha` on the fundamental tradeoff. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dict = {\n",
    "    \"alpha\": 10.0 ** np.arange(-3, 6, 1),\n",
    "    \"mean_train_scores\": list(),\n",
    "    \"mean_cv_valid_scores\": list(),\n",
    "}\n",
    "for alpha in scores_dict[\"alpha\"]:\n",
    "    pipe_ridge = make_pipeline(StandardScaler(), Ridge(alpha=alpha))\n",
    "    scores = cross_validate(pipe_ridge, X_train, y_train, return_train_score=True)\n",
    "    scores_dict[\"mean_train_scores\"].append(scores[\"train_score\"].mean())\n",
    "    scores_dict[\"mean_cv_valid_scores\"].append(scores[\"test_score\"].mean())\n",
    "\n",
    "results_df = pd.DataFrame(scores_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>mean_train_scores</th>\n",
       "      <th>mean_cv_valid_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.606567</td>\n",
       "      <td>0.605101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.606567</td>\n",
       "      <td>0.605101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.606567</td>\n",
       "      <td>0.605101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.606567</td>\n",
       "      <td>0.605102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.605100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.605696</td>\n",
       "      <td>0.604320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000.000</td>\n",
       "      <td>0.579432</td>\n",
       "      <td>0.578523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>0.431137</td>\n",
       "      <td>0.430868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100000.000</td>\n",
       "      <td>0.116167</td>\n",
       "      <td>0.115956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        alpha  mean_train_scores  mean_cv_valid_scores\n",
       "0       0.001           0.606567              0.605101\n",
       "1       0.010           0.606567              0.605101\n",
       "2       0.100           0.606567              0.605101\n",
       "3       1.000           0.606567              0.605102\n",
       "4      10.000           0.606557              0.605100\n",
       "5     100.000           0.605696              0.604320\n",
       "6    1000.000           0.579432              0.578523\n",
       "7   10000.000           0.431137              0.430868\n",
       "8  100000.000           0.116167              0.115956"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Here we do not really see overfitting but in general, \n",
    "- larger `alpha` $\\rightarrow$ likely to underfit\n",
    "- smaller `alpha` $\\rightarrow$ likely to overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Coefficients and intercept\n",
    "\n",
    "The model learns \n",
    "- **coefficients** ($w_i$) associated with each feature\n",
    "- **bias** ($b$) (intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the coefficients learned by the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_ridge = make_pipeline(StandardScaler(), Ridge(alpha=1.0))\n",
    "pipe_ridge.fit(X_train, y_train)\n",
    "coeffs = pipe_ridge.named_steps[\"ridge\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**coefficients ($w_i$) associated with each feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MedInc</th>\n",
       "      <td>0.827039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HouseAge</th>\n",
       "      <td>0.117058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AveRooms</th>\n",
       "      <td>-0.265273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AveBedrms</th>\n",
       "      <td>0.307521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Population</th>\n",
       "      <td>-0.003194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AveOccup</th>\n",
       "      <td>-0.039498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Latitude</th>\n",
       "      <td>-0.895963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Longitude</th>\n",
       "      <td>-0.866110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Coefficients\n",
       "MedInc          0.827039\n",
       "HouseAge        0.117058\n",
       "AveRooms       -0.265273\n",
       "AveBedrms       0.307521\n",
       "Population     -0.003194\n",
       "AveOccup       -0.039498\n",
       "Latitude       -0.895963\n",
       "Longitude      -0.866110"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=coeffs, index=california.feature_names, columns=[\"Coefficients\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**bias ($b$) (intercept)**\n",
    "- Model adds this amount irrespective of the feature values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0667579112160865"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_ridge.named_steps[\"ridge\"].intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "Remember how bias and coefficients are multiplied and added with the features to predict the target value:\n",
    "\n",
    "$\\hat{y} =$ <font color=\"red\">$w_1$</font> <font color=\"blue\">$x_1$ </font> $+ \\dots +$ <font color=\"red\">$w_d$</font> <font color=\"blue\">$x_d$</font> + <font  color=\"green\"> $b$</font>\n",
    "\n",
    "<br>\n",
    "\n",
    "Q: What's the prediction of the model if all features are zero?  \n",
    "A: ????\n",
    "\n",
    "Q: Can we use the **bias** to interpret model predictions?   \n",
    "A: ????\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trick question** to assess how deeply you understood pipelines:\n",
    "\n",
    "What the following two values? Why are they different?\n",
    "\n",
    "**(I'm not gonna answer this; wanna have you dig deeper into this on your own)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is this?\t [2.06675791]\n",
      "how about this?\t [-36.72994411]\n"
     ]
    }
   ],
   "source": [
    "print('what is this?\\t', pipe_ridge[1].predict(np.zeros((1,8))))\n",
    "\n",
    "print('how about this?\\t', pipe_ridge.predict(np.zeros((1,8))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ❓❓ Questions for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### (iClicker) Exercise 7.1 \n",
    "\n",
    "**iClicker cloud join link: https://join.iclicker.com/EMMJ**\n",
    "\n",
    "**Select all of the following statements which are TRUE.**\n",
    "\n",
    "- (A) Increasing the hyperparameter `alpha` of `Ridge` is likely to decrease model complexity.\n",
    "- (B) `Linear Regression` can be used with datasets that have multiple features.\n",
    "- (C) With Ridge, we learn one coefficient per training example.\n",
    "- (D) If you train a linear regression model on a 2-dimensional problem (2 features), the model will learn 3 parameters: one for each feature and one for the bias term. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers: ????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interpretation of coefficients "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- One of the main advantages of linear models is that they are relatively **easy to interpret**. \n",
    "- We have one coefficient per feature which kind of describes the role of the feature in the prediction according to the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two pieces of information in the coefficients based on\n",
    "\n",
    "- Sign\n",
    "- Magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sign of the coefficients\n",
    "\n",
    "In the example below, for instance: \n",
    "- MedInc (median income) has a **positive coefficient**\n",
    "    - the prediction will be proportional to the feature value; as MedInc gets **bigger**, the median house value gets **bigger** \n",
    "- AveRooms (Average number of rooms) has a **negative coefficient**\n",
    "    - the prediction will be inversely proportional to the feature value; as AveRooms gets **bigger**, the median house value gets **smaller**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MedInc</th>\n",
       "      <td>0.827039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HouseAge</th>\n",
       "      <td>0.117058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AveRooms</th>\n",
       "      <td>-0.265273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AveBedrms</th>\n",
       "      <td>0.307521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Population</th>\n",
       "      <td>-0.003194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AveOccup</th>\n",
       "      <td>-0.039498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Latitude</th>\n",
       "      <td>-0.895963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Longitude</th>\n",
       "      <td>-0.866110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Coefficients\n",
       "MedInc          0.827039\n",
       "HouseAge        0.117058\n",
       "AveRooms       -0.265273\n",
       "AveBedrms       0.307521\n",
       "Population     -0.003194\n",
       "AveOccup       -0.039498\n",
       "Latitude       -0.895963\n",
       "Longitude      -0.866110"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=coeffs, index=california.feature_names, columns=[\"Coefficients\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Magnitude of the coefficients\n",
    "\n",
    "- Bigger magnitude $\\rightarrow$ bigger impact on the prediction \n",
    "- In the example below, both MedInc and AveBedrms have a positive impact on the prediction but MedInc would have a bigger positive impact because it's feature value is going to be multiplied by a number with a bigger magnitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Latitude</th>\n",
       "      <td>-0.895963</td>\n",
       "      <td>0.895963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Longitude</th>\n",
       "      <td>-0.866110</td>\n",
       "      <td>0.866110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedInc</th>\n",
       "      <td>0.827039</td>\n",
       "      <td>0.827039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AveBedrms</th>\n",
       "      <td>0.307521</td>\n",
       "      <td>0.307521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AveRooms</th>\n",
       "      <td>-0.265273</td>\n",
       "      <td>0.265273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HouseAge</th>\n",
       "      <td>0.117058</td>\n",
       "      <td>0.117058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AveOccup</th>\n",
       "      <td>-0.039498</td>\n",
       "      <td>0.039498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Population</th>\n",
       "      <td>-0.003194</td>\n",
       "      <td>0.003194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            coefficient  magnitude\n",
       "Latitude      -0.895963   0.895963\n",
       "Longitude     -0.866110   0.866110\n",
       "MedInc         0.827039   0.827039\n",
       "AveBedrms      0.307521   0.307521\n",
       "AveRooms      -0.265273   0.265273\n",
       "HouseAge       0.117058   0.117058\n",
       "AveOccup      -0.039498   0.039498\n",
       "Population    -0.003194   0.003194"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"coefficient\": pipe_ridge.named_steps[\"ridge\"].coef_.tolist(),\n",
    "    \"magnitude\": np.absolute(pipe_ridge.named_steps[\"ridge\"].coef_.tolist()),\n",
    "}\n",
    "coef_df = pd.DataFrame(data, index=california.feature_names).sort_values(\n",
    "    \"magnitude\", ascending=False\n",
    ")\n",
    "coef_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Importance of scaling \n",
    "- **When you are interpreting the model coefficients, scaling is crucial**\n",
    "- If you do not scale the data, features with smaller magnitude are going to get coefficients with bigger magnitude whereas features with bigger scale are going to get coefficients with smaller magnitude.\n",
    "- That said, when you scale the data, feature values become hard to interpret for humans!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "```{Important}\n",
    "Take these coefficients with a grain of salt. They might not always match your intuitions. Also, they do not tell us about how the world works. They only tell us about how the prediction of your model works. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ❓❓ Questions for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Discuss the importance of scaling when interpreting linear regression coefficients. \n",
    "\n",
    "Answer: ???\n",
    "\n",
    "- What might be the meaning of complex vs simpler model in case of linear regression? \n",
    "\n",
    "Answer: ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Logistic regression [[video](https://youtu.be/56L5z_t22qE)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Logistic regression intuition \n",
    "\n",
    "- A linear model for **classification**. \n",
    "  - I repeat **LINEAR** model\n",
    "- Similar to linear regression, it learns weights associated with each feature and the bias. \n",
    "- It applies a **threshold** on the raw output to decide whether the class is positive or negative. \n",
    "- In this lecture we will focus on the following aspects of logistic regression.  \n",
    "    - `predict`, `predict_proba` \n",
    "    - how to use learned coefficients to interpret the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Motivating example (not a real example!)\n",
    "\n",
    "- Consider the problem of predicting sentiment expressed in movie reviews. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Training data for the motivating example\n",
    "\n",
    "\n",
    "<blockquote> \n",
    "    <p>Review 1: This movie was <b>excellent</b>! The performances were oscar-worthy!  👍 </p> \n",
    "    <p>Review 2: What a <b>boring</b> movie! I almost fell asleep twice while watching it. 👎 </p> \n",
    "    <p>Review 3: I enjoyed the movie. <b>Excellent</b>! 👍 </p>             \n",
    "</blockquote>  \n",
    "\n",
    "- Targets: positive 👍 and negative 👎\n",
    "- Features: words (e.g., *excellent*, *flawless*, *boring*)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Learned coefficients associated with all features\n",
    "\n",
    "- Suppose our vocabulary contains only the following 7 words. \n",
    "- A linear classifier learns **weights** or **coefficients** associated with the features (words in this example).  \n",
    "- Let's ignore bias for a bit. \n",
    "\n",
    "![](../img/words_coeff.png)\n",
    "\n",
    "<!-- <center>\n",
    "<img src='./img/words_coeff.png' width=\"250\" height=\"300\" />\n",
    "</center>  \n",
    " -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Predicting with learned weights \n",
    "- Use these learned coefficients to make predictions. For example, consider the following review $x_i$. \n",
    "<blockquote> \n",
    "It got a bit <b>boring</b> at times but the direction was <b>excellent</b> and the acting was <b>flawless</b>.\n",
    "</blockquote>\n",
    "- Feature vector for $x_i$: [1, 0, 1, 1, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](../img/words_coeff.png)\n",
    "<!-- <center>\n",
    "<img src='./img/words_coeff.png' width=\"250\" height=\"300\" />\n",
    "</center>  \n",
    " -->\n",
    "- $score(x_i) = $ coefficient(*boring*) $\\times 1$ + coefficient(*excellent*) $\\times 1$ + coefficient(*flawless*) $\\times 1$ = $-1.40 + 1.93 + 1.43 = 1.96$\n",
    "\n",
    "- $1.96 > 0$ so predict the review as positive 👍. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\n`load_boston` has been removed from scikit-learn since version 1.2.\n\nThe Boston housing prices dataset has an ethical problem: as\ninvestigated in [1], the authors of this dataset engineered a\nnon-invertible variable \"B\" assuming that racial self-segregation had a\npositive impact on house prices [2]. Furthermore the goal of the\nresearch that led to the creation of this dataset was to study the\nimpact of air quality but it did not give adequate demonstration of the\nvalidity of this assumption.\n\nThe scikit-learn maintainers therefore strongly discourage the use of\nthis dataset unless the purpose of the code is to study and educate\nabout ethical issues in data science and machine learning.\n\nIn this special case, you can fetch the dataset from the original\nsource::\n\n    import pandas as pd\n    import numpy as np\n\n    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n    target = raw_df.values[1::2, 2]\n\nAlternative datasets include the California housing dataset and the\nAmes housing dataset. You can load the datasets as follows::\n\n    from sklearn.datasets import fetch_california_housing\n    housing = fetch_california_housing()\n\nfor the California housing dataset and::\n\n    from sklearn.datasets import fetch_openml\n    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\nfor the Ames housing dataset.\n\n[1] M Carlisle.\n\"Racist data destruction?\"\n<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n\n[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n\"Hedonic housing prices and the demand for clean air.\"\nJournal of environmental economics and management 5.1 (1978): 81-102.\n<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplotting_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_logistic_regression\n\u001b[0;32m      2\u001b[0m x \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboring=1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexcellent=1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflawless=1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      3\u001b[0m w \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.40\u001b[39m, \u001b[38;5;241m1.93\u001b[39m, \u001b[38;5;241m1.43\u001b[39m]\n",
      "File \u001b[1;32m~\\Documents\\CPSC330-FW\\lectures\\AmirAbdi\\../code/.\\plotting_functions.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmglearn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimageio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m imread\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\mglearn\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plots\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tools\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplots\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cm3, cm2\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\mglearn\\plots.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot_animal_tree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_animal_tree\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot_rbf_svm_parameters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_svm\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot_knn_regression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_knn_regression\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot_knn_classification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_knn_classification\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot_2d_separator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_2d_classification, plot_2d_separator\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\mglearn\\plot_knn_regression.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsRegressor\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m euclidean_distances\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_wave\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot_helpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cm3\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_knn_regression\u001b[39m(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\mglearn\\datasets.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m signal\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_boston\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler, PolynomialFeatures\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmake_blobs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_blobs\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\datasets\\__init__.py:156\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_boston\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    106\u001b[0m     msg \u001b[38;5;241m=\u001b[39m textwrap\u001b[38;5;241m.\u001b[39mdedent(\n\u001b[0;32m    107\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m        `load_boston` has been removed from scikit-learn since version 1.2.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     )\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[name]\n",
      "\u001b[1;31mImportError\u001b[0m: \n`load_boston` has been removed from scikit-learn since version 1.2.\n\nThe Boston housing prices dataset has an ethical problem: as\ninvestigated in [1], the authors of this dataset engineered a\nnon-invertible variable \"B\" assuming that racial self-segregation had a\npositive impact on house prices [2]. Furthermore the goal of the\nresearch that led to the creation of this dataset was to study the\nimpact of air quality but it did not give adequate demonstration of the\nvalidity of this assumption.\n\nThe scikit-learn maintainers therefore strongly discourage the use of\nthis dataset unless the purpose of the code is to study and educate\nabout ethical issues in data science and machine learning.\n\nIn this special case, you can fetch the dataset from the original\nsource::\n\n    import pandas as pd\n    import numpy as np\n\n    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n    target = raw_df.values[1::2, 2]\n\nAlternative datasets include the California housing dataset and the\nAmes housing dataset. You can load the datasets as follows::\n\n    from sklearn.datasets import fetch_california_housing\n    housing = fetch_california_housing()\n\nfor the California housing dataset and::\n\n    from sklearn.datasets import fetch_openml\n    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\nfor the Ames housing dataset.\n\n[1] M Carlisle.\n\"Racist data destruction?\"\n<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n\n[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n\"Hedonic housing prices and the demand for clean air.\"\nJournal of environmental economics and management 5.1 (1978): 81-102.\n<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n"
     ]
    }
   ],
   "source": [
    "from plotting_functions import plot_logistic_regression\n",
    "x = [\"boring=1\", \"excellent=1\", \"flawless=1\"]\n",
    "w = [-1.40, 1.93, 1.43]\n",
    "display(plot_logistic_regression(x, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- So the prediction is based on the weighted sum of the input features.\n",
    "- Some feature are pulling the prediction towards positive sentiment and some are pulling it towards negative sentiment. \n",
    "- If the **coefficient of _boring_ had a bigger magnitude** or _excellent_ and _flawless_ had smaller magnitudes, we would have predicted \"neg\".   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def f(w_0):\n",
    "    x = [\"boring=1\", \"excellent=1\", \"flawless=1\"]\n",
    "    w = [-1.40, 1.93, 1.43]\n",
    "    w[0] = w_0\n",
    "    print(w)\n",
    "    display(plot_logistic_regression(x, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "interactive(\n",
    "    f,\n",
    "    w_0=widgets.FloatSlider(min=-6, max=2, step=0.5, value=-1.40),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In our case, for values for the coefficient of _boring_ < -3.36, the prediction would be negative. \n",
    "\n",
    "A linear model learns these coefficients or weights from the training data! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So a linear classifier is a linear function of the input `X`, followed by a **threshold**. \n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "z =& w_1x_1 + \\dots + w_dx_d + b\\\\\n",
    "=& w^Tx + b\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "$$\\hat{y} = \\begin{cases}\n",
    "         1, & \\text{if } z \\geq r\\\\\n",
    "         -1, & \\text{if } z < r\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Components of a linear classifier\n",
    "\n",
    "1. input features ($x_1, \\dots, x_d$)\n",
    "2. coefficients (weights) ($w_1, \\dots, w_d$)\n",
    "3. bias ($b$ or $w_0$) (can be used to offset your hyperplane)\n",
    "4. threshold ($r$)\n",
    "\n",
    "(In our example before, we **assumed** $r=0$ and $b=0$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Logistic regression on the cities data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_df = pd.read_csv(\"../data/canada_usa_cities.csv\")\n",
    "train_df, test_df = train_test_split(cities_df, test_size=0.2, random_state=123)\n",
    "X_train, y_train = train_df.drop(columns=[\"country\"]).values, train_df[\"country\"].values\n",
    "X_test, y_test = test_df.drop(columns=[\"country\"]).values, test_df[\"country\"].values\n",
    "\n",
    "cols = train_df.drop(columns=[\"country\"]).columns\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's try `LogisticRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ------- New Code ---------------\n",
    "lr = LogisticRegression()\n",
    "# ------- New Code ---------------\n",
    "\n",
    "scores = cross_validate(lr, X_train, y_train, return_train_score=True)\n",
    "print('Average Validation Score:', pd.DataFrame(scores)['test_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression seems to be doing better than dummy classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(scores)['test_score'].std())\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " But note that there is a lot of **variation** in the scores. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Accessing learned parameters\n",
    "\n",
    "- Recall that logistic regression learns the weights $w$ and bias or intercept $b$.\n",
    "\n",
    "- How to access these weights? \n",
    "    - Similar to `Ridge`, we can access the weights and intercept using `coef_` and `intercept_` attribute of the `LogisticRegression` object, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"Model weights: %s\" % (lr.coef_))  # these are the learned weights\n",
    "print(\"Model bias (intercept): %s\" % (lr.intercept_))  # this is the bias term\n",
    "data = {\"features\": cols, \"coefficients\": lr.coef_[0]}\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Both negative weights \n",
    "- The weight of latitude is larger in magnitude. \n",
    "- This makes sense because Canada as a country lies above the USA and so we expect latitude values to contribute more to a prediction than longitude. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Prediction with learned parameters\n",
    "\n",
    "Let's predict target of a test example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "example = X_test[0, :]\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Raw scores\n",
    "\n",
    "- Calculate the raw score as: ```y_hat = np.dot(w, x) + b```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    np.dot(\n",
    "        example,\n",
    "        lr.coef_.reshape(2),\n",
    "    )\n",
    "    + lr.intercept_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>\n",
    "\n",
    "------------\n",
    "\n",
    "**[Bonus]**\n",
    "\n",
    "How to get from the above to a decision?\n",
    "- Simple answer: \"zero\" is the threshold, if positive, it's USA, if negative, it's Canada\n",
    "- More complete answer: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{P}(y=\\text{USA}|X) = \\frac{1}{1 + exp(-X_iw - b)} = \\frac{1}{1 + exp(-(-1.97817876))} = \\frac{1}{1 + exp(1.97817876)} = 0.12151312$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict_proba([example])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn more here: https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Apply the threshold to the raw score. \n",
    "- Since the prediction is < 0, predict \"negative\". \n",
    "- What is a \"negative\" class in our context? \n",
    "- With logistic regression, the model randomly assigns one of the classes as a positive class and the other as negative. \n",
    "    - Usually it would alphabetically order the target and pick the first one as negative and second one as the positive class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The `classes_` attribute tells us which class is considered negative and which one is considered positive. - In this case, Canada is the negative class and USA is a positive class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- So based on the negative score above (-1.978), we would predict Canada. \n",
    "- Let's check the prediction given by the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict([example])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! The predictions match! We exactly know how the model is making predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decision boundary of logistic regression\n",
    "\n",
    "- The decision boundary of logistic regression is a **hyperplane** dividing the feature space in half. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train)\n",
    "mglearn.plots.plot_2d_separator(lr, X_train, fill=False, eps=0.5, alpha=0.7)\n",
    "plt.title(lr.__class__.__name__)\n",
    "plt.xlabel(\"longitude\")\n",
    "plt.ylabel(\"latitude\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- For $d=2$, the decision boundary is a line (1-dimensional)\n",
    "- For $d=3$, the decision boundary is a plane (2-dimensional)\n",
    "- For $d\\gt 3$, the decision boundary is a $d-1$-dimensional hyperplane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "for model, ax in zip(\n",
    "    [KNeighborsClassifier(), SVC(gamma=0.01), LogisticRegression()], axes\n",
    "):\n",
    "    clf = model.fit(X_train, y_train)\n",
    "    mglearn.plots.plot_2d_separator(\n",
    "        clf, X_train, fill=True, eps=0.5, ax=ax, alpha=0.4\n",
    "    )\n",
    "    mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train, ax=ax)\n",
    "    ax.set_title(clf.__class__.__name__)\n",
    "    ax.set_xlabel(\"longitude\")\n",
    "    ax.set_ylabel(\"latitude\")\n",
    "axes[0].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Notice a **LINEAR decision boundary** (a line in our case). \n",
    "- Compare it with  KNN or SVM RBF decision boundaries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Main hyperparameter of logistic regression \n",
    "\n",
    "- `C` is the main hyperparameter which controls the fundamental trade-off.\n",
    "- We won't really talk about the interpretation of this hyperparameter right now. \n",
    "- At a high level, the interpretation is similar to `C` of SVM RBF\n",
    "    - Similar to SVM, it is the **regularization** coefficient \n",
    "    - Similar to SVM, it is the **inverse of regularization strength**\n",
    "    - Similar to SVM, \n",
    "      - smaller `C` $\\rightarrow$ might lead to underfitting\n",
    "      - bigger `C` $\\rightarrow$ might lead to overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "scores_dict = {\n",
    "    \"C\": 10.0 ** np.arange(-4, 6, 1),\n",
    "    \"mean_train_scores\": list(),\n",
    "    \"mean_cv_scores\": list(),\n",
    "}\n",
    "for C in scores_dict[\"C\"]:\n",
    "    lr = LogisticRegression(C=C)\n",
    "    scores = cross_validate(lr, X_train, y_train, return_train_score=True)\n",
    "    scores_dict[\"mean_train_scores\"].append(scores[\"train_score\"].mean())\n",
    "    scores_dict[\"mean_cv_scores\"].append(scores[\"test_score\"].mean())\n",
    "\n",
    "results_df = pd.DataFrame(scores_dict)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "for model, ax in zip(\n",
    "    [LogisticRegression(C=0.0001), LogisticRegression(C=10000)], axes\n",
    "):\n",
    "    clf = model.fit(X_train, y_train)\n",
    "    mglearn.plots.plot_2d_separator(\n",
    "        clf, X_train, fill=True, eps=0.5, ax=ax, alpha=0.4\n",
    "    )\n",
    "    mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train, ax=ax)\n",
    "    ax.set_title(f\"{clf.__class__.__name__}(C={clf.C}), valid_score={float(results_df[results_df.C==clf.C].mean_cv_scores):0.4}\")\n",
    "    ax.set_xlabel(\"longitude\")\n",
    "    ax.set_ylabel(\"latitude\")\n",
    "axes[0].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Predicting probability scores [[video](https://youtu.be/_OAK5KiGLg0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `predict_proba`\n",
    "\n",
    "- So far in the context of classification problems, we focused on getting \"hard\" predictions. \n",
    "- Very often it's useful to know \"soft\" predictions, i.e., how confident the model is with a given prediction.  \n",
    "- For most of the `scikit-learn` classification models we can access this **confidence score** or **probability** score using a method called `predict_proba`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at probability scores of logistic regression model for our test example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=123)\n",
    "lr.fit(X_train, y_train)\n",
    "lr.predict([example])  # hard prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict_proba([example])  # soft prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The output of `predict_proba` is the probability of each class. \n",
    "- In binary classification, we get probabilities associated with both classes (even though this information is redundant). \n",
    "- The first entry is the estimated probability of the first class and the second entry is the estimated probability of the second class from `model.classes_`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Because it's a probability, the sum of the entries for both classes should always sum to 1. \n",
    "- Since the probabilities for the two classes sum to 1, exactly one of the classes will have a score >=0.5, which is going to be our predicted class.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### How does logistic regression calculate these probabilities? \n",
    "\n",
    "- The weighted sum $w_1x_1 + \\dots + w_dx_d + b$ gives us \"raw model output\".\n",
    "- For linear regression this would have been the prediction.\n",
    "- For logistic regression, you check the **sign** of this value.\n",
    "  - If positive (or 0), predict $+1$; if negative, predict $-1$.\n",
    "  - These are \"hard predictions\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- You can also have \"soft predictions\", aka **predicted probabilities**. \n",
    "  - To convert the raw model output into probabilities, instead of taking the sign, we apply the **sigmoid**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Sigmoid Function (special/standard form of Logistic Function)\n",
    "- The sigmoid function \"squashes\" the raw model output from any number to the range $[0,1]$ using the following formula, where $x$ is the raw model output. \n",
    "$$\\frac{1}{1+e^{-x}}$$\n",
    "- Then we can interpret the output as probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "raw_model_output = np.linspace(-8, 8, 1000)\n",
    "plt.plot(raw_model_output, sigmoid(raw_model_output))\n",
    "plt.plot([0, 0], [0, 0.5], \"--k\")\n",
    "plt.plot([-8, 0], [0.5, 0.5], \"--k\")\n",
    "plt.xlabel(\"raw model output, $w^Tx$\")\n",
    "plt.ylabel(\"predicted probability\")\n",
    "plt.title(\"the sigmoid function\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Recall our hard predictions that check the sign of $w^Tx$, or, in other words, whether or not it is $\\geq 0$.\n",
    "  - The threshold $w^Tx=0$ corresponds to $p=0.5$. \n",
    "  - In other words, if our predicted probability is $\\geq 0.5$ then our hard prediction is $+1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's get the probability score by calling sigmoid on the raw model output for our test example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid(\n",
    "    np.dot(\n",
    "        example,\n",
    "        lr.coef_.reshape(\n",
    "            2,\n",
    "        ),\n",
    "    )\n",
    "    + lr.intercept_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the probability score of the positive class, which is USA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict_proba([example])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `predict_proba`, we get the same probability score for USA!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Let's visualize probability scores for some examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    \"y\": y_train[:12],\n",
    "    \"y_hat\": lr.predict(X_train[:12]).tolist(),\n",
    "    \"probabilities\": lr.predict_proba(X_train[:12]).tolist(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The actual `y` and `y_hat` match in most of the cases but in some cases the model is more confident about the prediction than others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Least confident cases \n",
    "\n",
    "Let's examine some cases where the model is least confident about the prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_confident_X = X_train[[127, 141]]\n",
    "least_confident_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "least_confident_y = y_train[[127, 141]]\n",
    "least_confident_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "probs = lr.predict_proba(least_confident_X)\n",
    "\n",
    "data_dict = {\n",
    "    \"y\": least_confident_y,\n",
    "    \"y_hat\": lr.predict(least_confident_X).tolist(),\n",
    "    \"probability score (Canada)\": probs[:, 0],\n",
    "    \"probability score (USA)\": probs[:, 1],\n",
    "}\n",
    "pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mglearn.discrete_scatter(\n",
    "    least_confident_X[:, 0],\n",
    "    least_confident_X[:, 1],\n",
    "    least_confident_y,\n",
    "    markers=\"o\",\n",
    ")\n",
    "mglearn.plots.plot_2d_separator(lr, X_train, fill=True, eps=0.5, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The points are close to the decision boundary** which makes sense. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Most confident cases \n",
    "\n",
    "Let's examine some cases where the model is most confident about the prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_confident_X = X_train[[37, 4]]\n",
    "most_confident_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_confident_y = y_train[[37, 165]]\n",
    "most_confident_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "probs = lr.predict_proba(most_confident_X)\n",
    "\n",
    "data_dict = {\n",
    "    \"y\": most_confident_y,\n",
    "    \"y_hat\": lr.predict(most_confident_X).tolist(),\n",
    "    \"probability score (Canada)\": probs[:, 0],\n",
    "    \"probability score (USA)\": probs[:, 1],\n",
    "}\n",
    "pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_confident_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mglearn.discrete_scatter(\n",
    "    most_confident_X[:, 0],\n",
    "    most_confident_X[:, 1],\n",
    "    most_confident_y,\n",
    "    markers=\"o\",\n",
    ")\n",
    "mglearn.plots.plot_2d_separator(lr, X_train, fill=True, eps=0.5, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The points are far away from the decision boundary which makes sense. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Over confident cases\n",
    "\n",
    "Let's examine some cases where the model is **confident** about the prediction but the **prediction is wrong**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(X_train[:,1] > 55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_confident_X = X_train[[98, 25]]\n",
    "over_confident_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_confident_y = y_train[[0, 1]]\n",
    "over_confident_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "probs = lr.predict_proba(over_confident_X)\n",
    "\n",
    "data_dict = {\n",
    "    \"y\": over_confident_y,\n",
    "    \"y_hat\": lr.predict(over_confident_X).tolist(),\n",
    "    \"probability score (Canada)\": probs[:, 0],\n",
    "    \"probability score (USA)\": probs[:, 1],\n",
    "}\n",
    "pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mglearn.discrete_scatter(\n",
    "    over_confident_X[:, 0],\n",
    "    over_confident_X[:, 1],\n",
    "    over_confident_y,\n",
    "    markers=\"o\",\n",
    ")\n",
    "mglearn.plots.plot_2d_separator(lr, X_train, fill=True, eps=0.5, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The cities are **far away from the decision boundary**. \n",
    "  - So the model is pretty **confident** about the prediction. \n",
    "- But the cities are likely to be from Alaska and our linear model is not able to capture that this part belong to the USA and not Canada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Below we are using colour to represent prediction probabilities. If you are closer to the border, the model is less confident whereas the model is more confident about the mainland cities, which makes sense.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(18, 5))\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "for ax in axes:\n",
    "    mglearn.discrete_scatter(\n",
    "        X_train[:, 0], X_train[:, 1], y_train, markers=\"o\", ax=ax\n",
    "    )\n",
    "    ax.set_xlabel(\"longitude\")\n",
    "    ax.set_ylabel(\"latitude\")\n",
    "\n",
    "axes[0].legend([\"Train class 0\", \"Train class 1\"], ncol=2, loc=(0.1, 1.1))\n",
    "\n",
    "mglearn.plots.plot_2d_separator(\n",
    "    lr, X_train, fill=True, eps=0.5, ax=axes[0], alpha=0.5\n",
    ")\n",
    "mglearn.plots.plot_2d_separator(\n",
    "    lr, X_train, fill=False, eps=0.5, ax=axes[1], alpha=0.5\n",
    ")\n",
    "scores_image = mglearn.tools.plot_2d_scores(\n",
    "    lr, X_train, eps=0.5, ax=axes[1], alpha=0.5, cm=plt.cm.coolwarm\n",
    ")\n",
    "cbar = plt.colorbar(scores_image, ax=axes.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sometimes a complex model that is overfitted, tends to make more confident predictions, even if they are wrong, whereas a simpler model tends to make predictions with more uncertainty. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To summarize, \n",
    "- With hard predictions, we only know the class. \n",
    "- With probability scores we know how confident the model is with certain predictions, which can be useful in understanding the model better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ❓❓ Questions for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### (iClicker) Exercise 7.2 \n",
    "\n",
    "**iClicker cloud join link: https://join.iclicker.com/EMMJ**\n",
    "\n",
    "**Select all of the following statements which are TRUE.**\n",
    "\n",
    "- (A) Increasing logistic regression's `C` hyperparameter increases model complexity.\n",
    "- (B) The raw output score can be used to calculate the probability score for a given prediction. \n",
    "- (C) For linear classifier trained on $d$ features, the decision boundary is a $d-1$-dimensional hyperparlane.  \n",
    "- (D) A linear model is likely to be uncertain about the data points close to the decision boundary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: ????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><br>\n",
    "**[Bonus Question] How does Linear Regression (with or without regularizaiton) and Logistic Regression calcualte Weights ($w_i$) and Bias ($b$)?**\n",
    "\n",
    "$\\hat{y} =$ <font color=\"red\">$w_1$</font> <font color=\"blue\">$x_1$ </font> $+ \\dots +$ <font color=\"red\">$w_d$</font> <font color=\"blue\">$x_d$</font> + <font  color=\"green\"> $b$</font>\n",
    "\n",
    "Answers are here: https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "\n",
    "TL;DR: Simplest solver is **Ordinary Least Squares**. \n",
    "\n",
    "<br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linear SVM \n",
    "\n",
    "- We have seen non-linear SVM with **RBF kernel** before. This is the default SVC model in `sklearn` because it tends to work better in many cases. \n",
    "- There is also a **linear SVM**. You can pass `kernel=\"linear\"` to create a linear SVM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cities_df = pd.read_csv(\"../data/canada_usa_cities.csv\")\n",
    "train_df, test_df = train_test_split(cities_df, test_size=0.2, random_state=123)\n",
    "X_train, y_train = train_df.drop(columns=[\"country\"]).values, train_df[\"country\"].values\n",
    "X_test, y_test = test_df.drop(columns=[\"country\"]).values, test_df[\"country\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "for (model, ax) in zip([SVC(gamma=0.01), SVC(kernel=\"linear\"), LogisticRegression(C=1)], axes):\n",
    "    mglearn.discrete_scatter(\n",
    "        X_train[:, 0], X_train[:, 1], y_train, markers=\"o\", ax=ax\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    ax.set_xlabel(\"longitude\")\n",
    "    ax.set_ylabel(\"latitude\")\n",
    "    mglearn.plots.plot_2d_separator(\n",
    "        model, X_train, fill=True, eps=0.5, ax=ax, alpha=0.5\n",
    "    )\n",
    "\n",
    "axes[0].set_title(\"SVM RBF\")\n",
    "axes[1].set_title(\"Linear SVM\");\n",
    "axes[2].set_title(\"LogisticRegression\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- `predict` method of linear SVM and logistic regression works the same way. \n",
    "- We can get `coef_` associated with the features and `intercept_` using a Linear SVM model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "linear_svc = SVC(kernel=\"linear\")\n",
    "linear_svc.fit(X_train, y_train)\n",
    "print(\"Model weights: %s\" % (linear_svc.coef_))\n",
    "print(\"Model bias (intercept): %s\" % (linear_svc.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "Let's compare that with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"Model weights: %s\" % (lr.coef_))\n",
    "print(\"Model bias (intercept): %s\" % (lr.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that the coefficients and intercept are slightly different for logistic regression. \n",
    "- This is because the `fit` for linear SVM and logistic regression are different. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Break (5 min)\n",
    "\n",
    "![](../img/eva-coffee.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Demo: Model interpretation of linear classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- One of the primary advantage of linear classifiers is their ability to **interpret models**. \n",
    "- For example, with the sign and magnitude of learned coefficients we could answer questions such as which features are driving the prediction to which direction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We'll demonstrate this by training `LogisticRegression` on the famous [IMDB movie review](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) dataset. The dataset is a bit large for demonstration purposes. So I am going to put a big portion of it in the test split to speed things up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df = pd.read_csv(\"../data/imdb_master.csv\", encoding=\"ISO-8859-1\")\n",
    "imdb_df = imdb_df[imdb_df[\"label\"].str.startswith((\"pos\", \"neg\"))]\n",
    "imdb_df.drop([\"Unnamed: 0\", \"type\", \"file\"], axis=1, inplace=True)\n",
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's clean up the data a bit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def replace_tags(doc):\n",
    "    doc = doc.replace(\"<br />\", \" \")\n",
    "    doc = re.sub(\"https://\\S*\", \"\", doc)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "imdb_df[\"review_pp\"] = imdb_df[\"review\"].apply(replace_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are we breaking the Golden rule here? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's split the data and create bag of words representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(imdb_df, test_size=0.9, random_state=123)\n",
    "X_train, y_train = train_df[\"review_pp\"], train_df[\"label\"]\n",
    "X_test, y_test = test_df[\"review_pp\"], test_df[\"label\"]\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(stop_words=\"english\", max_features=10000)\n",
    "bow = vec.fit_transform(X_train)\n",
    "bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Examining the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The vocabulary (mapping from feature indices to actual words) can be obtained using `get_feature_names()` on the `CountVectorizer` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vec.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "vocab[0:10]  # first few words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "vocab[2000:2010]  # some middle words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "vocab[::500]  # words with a step of 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model building on the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's try logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = make_pipeline(\n",
    "    CountVectorizer(stop_words=\"english\", max_features=10000),\n",
    "    LogisticRegression(max_iter=1000),\n",
    ")\n",
    "scores = cross_validate(pipe_lr, X_train, y_train, return_train_score=True)\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "Seems like we are **overfitting**. Let's optimize the hyperparameter `C`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "scores_dict = {\n",
    "    \"C\": 10.0 ** np.arange(-3, 3, 1),\n",
    "    \"mean_train_scores\": list(),\n",
    "    \"mean_cv_scores\": list(),\n",
    "}\n",
    "for C in scores_dict[\"C\"]:\n",
    "    pipe_lr = make_pipeline(\n",
    "        CountVectorizer(stop_words=\"english\", max_features=10000),\n",
    "        LogisticRegression(max_iter=1000, C=C),\n",
    "    )\n",
    "    scores = cross_validate(pipe_lr, X_train, y_train, return_train_score=True)\n",
    "    scores_dict[\"mean_train_scores\"].append(scores[\"train_score\"].mean())\n",
    "    scores_dict[\"mean_cv_scores\"].append(scores[\"test_score\"].mean())\n",
    "\n",
    "results_df = pd.DataFrame(scores_dict)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "optimized_C = results_df[\"C\"].iloc[np.argmax(results_df[\"mean_cv_scores\"])]\n",
    "print(\n",
    "    \"The maximum validation score is %0.3f at C = %0.2f \"\n",
    "    % (\n",
    "        np.max(results_df[\"mean_cv_scores\"]),\n",
    "        optimized_C,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's train a model on the full training set with the optimized hyperparameter values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pipe_lr = make_pipeline(\n",
    "    CountVectorizer(stop_words=\"english\", max_features=10000),\n",
    "    LogisticRegression(max_iter=1000, C=optimized_C),\n",
    ")\n",
    "pipe_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Examining learned coefficients "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The learned coefficients are exposed by the `coef_` attribute of [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = np.array(pipe_lr.named_steps[\"countvectorizer\"].get_feature_names_out())\n",
    "coeffs = pipe_lr.named_steps[\"logisticregression\"].coef_.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_coeff_df = pd.DataFrame(coeffs, index=feature_names, columns=[\"Coefficient\"])\n",
    "word_coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Let's sort the coefficients in descending order. \n",
    "- Interpretation\n",
    "    - if $w_j > 0$ then increasing $x_{ij}$ moves us toward predicting $+1$. \n",
    "    - if $w_j < 0$ then increasing $x_{ij}$ moves us toward predicting $-1$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_coeff_df.sort_values(by=\"Coefficient\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The coefficients make sense!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's visualize the top 20 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.tools.visualize_coefficients(coeffs, feature_names, n_top_features=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's explore prediction of the following new review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_review = (\n",
    "    \"It got a bit boring at times but the direction was excellent and the acting was flawless. \"\n",
    "    \"Overall I enjoyed the movie and I highly recommend it!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_vec = pipe_lr.named_steps[\"countvectorizer\"].transform([fake_review])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's get prediction probability scores of the fake review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr.predict_proba([fake_review])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "The model is 83.5% confident that it's a **positive** review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr.predict([fake_review])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br><br><br><br>\n",
    "We can find **which of the vocabulary words are present**in this review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feat_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names[226], feature_names[1007], feature_names[1133], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_ex = feat_vec.toarray().ravel().astype(bool)\n",
    "words_in_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many of the words are in this review?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(words_in_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "np.array(feature_names)[words_in_ex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_df = pd.DataFrame(\n",
    "    data=coeffs[words_in_ex],\n",
    "    index=np.array(feature_names)[words_in_ex],\n",
    "    columns=[\"Coefficient\"],\n",
    ")\n",
    "ex_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's visualize how the words with positive and negative coefficients are driving the hard prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.tools.visualize_coefficients(\n",
    "    coeffs[words_in_ex], np.array(feature_names)[words_in_ex], n_top_features=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Just some helper function to further explore data\n",
    "def plot_coeff_example(feat_vect, coeffs, feature_names):\n",
    "    words_in_ex = feat_vec.toarray().ravel().astype(bool)\n",
    "\n",
    "    ex_df = pd.DataFrame(\n",
    "        data=coeffs[words_in_ex],\n",
    "        index=np.array(feature_names)[words_in_ex],\n",
    "        columns=[\"Coefficient\"],\n",
    "    )\n",
    "    return ex_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "**[ Read this section at home on your own ]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Most positive review "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remember that you can look at the probabilities (confidence) of the classifier's prediction using the `model.predict_proba` method.\n",
    "- Can we find the reviews where our classifier is most confident or least confident?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_probs = pipe_lr.predict_proba(X_train)[\n",
    "    :, 1\n",
    "]  # only get probabilities associated with pos class\n",
    "pos_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's get the index of the example where the classifier is most confident (highest `predict_proba` score for positive). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_positive = np.argmax(pos_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.iloc[most_positive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"True target: %s\\n\" % (y_train.iloc[most_positive]))\n",
    "print(\"Predicted target: %s\\n\" % (pipe_lr.predict(X_train.iloc[[most_positive]])[0]))\n",
    "print(\"Prediction probability: %0.4f\" % (pos_probs[most_positive]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's examine the features associated with the review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_vec = pipe_lr.named_steps[\"countvectorizer\"].transform(\n",
    "    X_train.iloc[[most_positive]]\n",
    ")\n",
    "words_in_ex = feat_vec.toarray().ravel().astype(bool)\n",
    "mglearn.tools.visualize_coefficients(\n",
    "    coeffs[words_in_ex], np.array(feature_names)[words_in_ex], n_top_features=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The review has both positive and negative words but the words with **positive** coefficients win in this case! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Most negative review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_probs = pipe_lr.predict_proba(X_train)[\n",
    "    :, 0\n",
    "]  # only get probabilities associated with pos class\n",
    "neg_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_negative = np.argmax(neg_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Review: %s\\n\" % (X_train.iloc[[most_negative]]))\n",
    "print(\"True target: %s\\n\" % (y_train.iloc[most_negative]))\n",
    "print(\"Predicted target: %s\\n\" % (pipe_lr.predict(X_train.iloc[[most_negative]])[0]))\n",
    "print(\"Prediction probability: %0.4f\" % (pos_probs[most_negative]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "feat_vec = pipe_lr.named_steps[\"countvectorizer\"].transform(\n",
    "    X_train.iloc[[most_negative]]\n",
    ")\n",
    "words_in_ex = feat_vec.toarray().ravel().astype(bool)\n",
    "mglearn.tools.visualize_coefficients(\n",
    "    coeffs[words_in_ex], np.array(feature_names)[words_in_ex], n_top_features=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The review has both positive and negative words but the words with negative coefficients win in this case! \n",
    "\n",
    "-----------\n",
    "\n",
    "<br><br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ❓❓ Questions for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "source": [
    "#### Question for you to ponder on \n",
    "\n",
    "- Is it possible to identify **most important features** using $k$-NNs? What about decision trees?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary of linear models \n",
    "\n",
    "- Linear regression is a linear model for regression whereas logistic regression is a linear model for classification. \n",
    "- Both these models learn one coefficient per feature, plus an intercept. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Main hyperparameters \n",
    "- The main hyperparameter is the \"***regularization**\" hyperparameter controlling the fundamental tradeoff. \n",
    "    - Logistic Regression: `C`\n",
    "    - Linear SVM: `C` \n",
    "    - Ridge: `alpha`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interpretation of coefficients in linear models \n",
    "- the $j$th coefficient tells us how feature $j$ affects the prediction\n",
    "- if $w_j > 0$ then increasing $x_{ij}$ moves us toward predicting $+1$\n",
    "- if $w_j < 0$ then increasing $x_{ij}$ moves us toward prediction $-1$\n",
    "- if $w_j == 0$ then the feature is not used in making a prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Strengths of linear models \n",
    "\n",
    "- **Fast** to train and predict\n",
    "- **Scale** to large datasets and work well with sparse data \n",
    "- Relatively easy to understand and **interpret** the predictions\n",
    "- **Perform relatively well (or OK!)** when there is a large number of features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Limitations of linear models \n",
    "\n",
    "- Is your data \"linearly separable\"? \n",
    "  - Can you draw a hyperplane between these datapoints that separates them with 0 error?\n",
    "    - If the training examples can be separated by a linear decision rule, they are **linearly separable**.\n",
    "- Linear models fail if data is complex and **NOT** linearly separable or  **NO linear relationship** between features and target.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A few questions you might be thinking about\n",
    "- How often the real-life data is linearly separable?\n",
    "- Is the following XOR function linearly separable?  \n",
    "\n",
    "| $$x_1$$ | $$x_2$$ | target|\n",
    "|---------|---------|---------|\n",
    "| 0 | 0  | 0|\n",
    "| 0 | 1  | 1|\n",
    "| 1 | 0  | 1|\n",
    "| 1 | 1  | 0|    \n",
    "\n",
    "- Are linear classifiers very limiting because of this?     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
