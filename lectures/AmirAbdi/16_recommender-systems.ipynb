{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](../img/330-banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Lecture 16: Recommender Systems\n",
    "-------------\n",
    "\n",
    "UBC 2022-23 W2\n",
    "\n",
    "Instructor: Amir Abdi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../code/.\")\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# plt.style.use(\"seaborn\")\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_colwidth\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Learning outcomes <a name=\"lo\"></a>\n",
    "\n",
    "From this lecture, students are expected to be able to:\n",
    "\n",
    "- State the problem of **recommender systems**. \n",
    "- Describe components of a **utility matrix**. \n",
    "- Create a utility matrix given ratings data. \n",
    "- Describe a common approach to **evaluate recommender systems**. \n",
    "- Implement some baseline approaches to complete the utility matrix. \n",
    "- Explain the idea of **collaborative filtering**. \n",
    "- Explain some serious consequences of recommendation systems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Announcements\n",
    "\n",
    "- HW6 was due last night\n",
    "- HW7, due Mar 22, 11:59pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recommender systems motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is a recommender system? \n",
    "\n",
    "- A recommender or a recommendation system **recommends** a particular product or service to users they are likely to consume. \n",
    "\n",
    "![](../img/recommendation_system.png)\n",
    "\n",
    "<!-- <img src=\"img/recommendation_system.png\" alt=\"\" height=\"900\" width=\"900\">  -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Recommender Systems\n",
    "- A client goes to Amazon to buy products. \n",
    "- Amazon has some information about the client. They also have information about other clients buying similar products. \n",
    "- What should they recommend to the client, so that they buy more products? \n",
    "- There's no \"right\" answer (**no actual groudntruth label**). \n",
    "- The whole idea is to **understand user behavior** and **similarities across users** in order to recommend them products they are likely to consume. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/utility_matrix.png\" alt=\"\" width=\"500\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why should we care about recommendation systems? \n",
    "\n",
    "- Almost everything we buy or consume today is in some way or the other influenced by recommendation systems. \n",
    "    - Music (Spotify), videos (YouTube), news, books and products (Amazon), movies (Netflix), jokes, restaurants, dating , friends (Facebook), professional connections (Linkedin)\n",
    "- Recommendation systems are at the core of the success of many companies. \n",
    "    - Amazon\n",
    "    - [Netflix](https://help.netflix.com/en/node/100639)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What kind of data we need to build recommendation systems? \n",
    "\n",
    "- **User ratings data** (most common)\n",
    "- **Features related to items or users** \n",
    "- Customer purchase history data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Main approaches\n",
    "\n",
    "- Collaborative filtering \n",
    "  - \"Unsupervised\" learning \n",
    "  - We only have labels $y_{ij}$ (rating of user $i$ for item $j$). \n",
    "  - We learn features.  \n",
    "- Content-based recommenders \n",
    "    - Supervised learning\n",
    "    - Extract features $x_i$ of users and/or items and building a model to predict rating $y_i$ given $x_i$. \n",
    "    - Apply **model.predict()** to predict for new users/items. \n",
    "- Hybrid \n",
    "    - Combining collaborative filtering with content-based filtering\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Netflix prize\n",
    "\n",
    "<!-- ![](../img/netflix.png) -->\n",
    "<img src=\"../img/netflix.png\" width=\"600\">\n",
    "\n",
    "[Source](https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Netflix prize\n",
    "\n",
    "- 100M ratings from 0.5M users on 18k movies.\n",
    "- Grand prize was **\\$1M for first team to reduce squared error at least by 10%**.\n",
    "- Winning entry (and most entries) used collaborative filtering:\n",
    "    - Methods that only looks at ratings, not features of movies/users.\n",
    "- A simple collaborative filtering method that does really well:\n",
    "   - Now adopted by many companies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recommender systems problem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Problem formulation\n",
    "\n",
    "- Most often the data for recommender systems come in as **ratings** for a set of items from a set of users. \n",
    "- We have two entities: $N$ **users** and $M$ **items**. \n",
    "- **Users** are consumers. \n",
    "- **Items** are the products or services offered.  \n",
    "    - E.g., movies (Netflix), books (Amazon), songs (spotify), people (tinder)  \n",
    "    \n",
    "<!-- ![](../img/utility_matrix.png) -->\n",
    "\n",
    "<img src=\"../img/utility_matrix.png\" alt=\"\" height=\"900\" width=\"900\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Utility matrix \n",
    "\n",
    "- A **utility matrix** is the matrix that captures **interactions** between $N$ **users** and $M$ **items**. \n",
    "- The interaction may come in different forms: \n",
    "    - ratings, clicks, purchases\n",
    "\n",
    "<!-- ![](../img/utility_matrix.png) -->\n",
    "\n",
    "<!-- <img src=\"../img/utility_mat.png\" alt=\"\" height=\"900\" width=\"900\">  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Utility matrix\n",
    "\n",
    "- Below is a toy utility matrix. Here $N$ = 6 and $M$ = 5.  \n",
    "- Each entry $y_{ij}$ ($i^{th}$ row and $j^{th}$ column) denotes the rating given by the user $i$ to item $j$. \n",
    "- We represent users in terms of items and items in terms of users. \n",
    "\n",
    "<!-- ![](../img/utility_matrix.png) -->\n",
    "\n",
    "<!-- <img src=\"../img/utility_matrix.png\" alt=\"\" height=\"900\" width=\"900\">  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sparsity of utility matrix\n",
    "\n",
    "- The utility matrix **can be very sparse** because **usually users only interact with a few items**. \n",
    "- For example: \n",
    "    - all Netflix users will have rated only a small percentage of content available on Netflix\n",
    "    - all amazon clients will have rated only a small fraction of items among all items available on Amazon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What do we predict? \n",
    "Given a utility matrix of $N$ users and $M$ items, **complete the utility matrix**. In other words, **predict missing values in the matrix**. \n",
    "\n",
    "<!-- ![](../img/utility_matrix.png) -->\n",
    "\n",
    "<img src=\"../img/utility_matrix.png\" alt=\"\" height=\"900\" width=\"900\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Once we have predicted ratings, we can recommend items to users they are likely to rate higher. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example dataset: [Jester 1.7M jokes ratings dataset](https://www.kaggle.com/vikashrajluhaniwal/jester-17m-jokes-ratings-dataset?select=jester_ratings.csv)\n",
    "\n",
    "- We'll use a sample of [Jester 1.7M jokes ratings dataset](https://www.kaggle.com/vikashrajluhaniwal/jester-17m-jokes-ratings-dataset) to demonstrate different recommendation systems. \n",
    "\n",
    "The dataset comes with two CSVs\n",
    "- A CSV containing ratings (-10.0 to +10.0) of 150 jokes from 59,132 users. \n",
    "- A CSV containing joke IDs and the actual text of jokes. \n",
    "\n",
    "> Some jokes might be offensive. Please do not look too much into the actual text data if you are sensitive to such language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Recommendation systems are most effective when you have a large amount of data.\n",
    "- But we are only taking a sample here for speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/jester_ratings.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/jester_ratings.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m ratings_full \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal number of users: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(ratings_full\u001b[38;5;241m.\u001b[39muserId\u001b[38;5;241m.\u001b[39munique()))\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/jester_ratings.csv'"
     ]
    }
   ],
   "source": [
    "filename = \"../data/jester_ratings.csv\"\n",
    "ratings_full = pd.read_csv(filename)\n",
    "\n",
    "print('total number of users: ', len(ratings_full.userId.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit to at most 4000 users\n",
    "ratings = ratings_full[ratings_full[\"userId\"] <= 4000]\n",
    "print('total number of users: ', len(ratings.userId.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_key = \"userId\"\n",
    "item_key = \"jokeId\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dataset stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_stats(ratings, item_key=\"jokeId\", user_key=\"userId\"):\n",
    "    print(\"Number of ratings:\", len(ratings))\n",
    "    print(\"Average rating:  %0.3f\" % (np.mean(ratings[\"rating\"])))\n",
    "    N = len(np.unique(ratings[user_key]))\n",
    "    M = len(np.unique(ratings[item_key]))\n",
    "    print(\"Number of users (N): %d\" % N)\n",
    "    print(\"Number of items (M): %d\" % M)\n",
    "    print(\"Fraction non-nan ratings: %0.3f\" % (len(ratings) / (N * M)))\n",
    "    return N, M\n",
    "\n",
    "N, M = get_stats(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Creating utility matrix\n",
    "\n",
    "- Let's construct utility matrix with `number of users` rows and `number of items` columns from the ratings data. \n",
    "\n",
    "> Note we are constructing a non-sparse matrix for demonstration purpose here. In real life it's recommended that you work with sparse matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapper = dict(zip(np.unique(ratings[user_key]), list(range(N))))\n",
    "item_mapper = dict(zip(np.unique(ratings[item_key]), list(range(M))))\n",
    "user_inverse_mapper = dict(zip(list(range(N)), np.unique(ratings[user_key])))\n",
    "item_inverse_mapper = dict(zip(list(range(M)), np.unique(ratings[item_key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Function to create a utility matrix\n",
    "def create_Y_from_ratings(\n",
    "    data, N, M, user_mapper, item_mapper, user_key=\"userId\", item_key=\"jokeId\"\n",
    "):  \n",
    "    Y = np.zeros((N, M))\n",
    "    Y.fill(np.nan)\n",
    "    for index, val in data.iterrows():\n",
    "        n = user_mapper[val[user_key]]\n",
    "        m = item_mapper[val[item_key]]\n",
    "        Y[n, m] = val[\"rating\"]\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Utility matrix for the example problem\n",
    "- Rows represent users.\n",
    "- Columns represent items (jokes in our case).\n",
    "- Each cell gives the rating given by the user to the corresponding joke. \n",
    "- Users are features for jokes and jokes are features for users.\n",
    "- We want to predict the missing entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_mat = create_Y_from_ratings(ratings, N, M, user_mapper, item_mapper)\n",
    "Y_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Y_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple Solutions (Baselines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Recall that our goal is to predict missing entries in the utility matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluation\n",
    "\n",
    "- We'll try a number of methods to do this. \n",
    "- Although there is no notion of \"accurate\" recommendations, we need a way to **evaluate** our predictions so that we'll be able to compare different methods.\n",
    "- Although we are doing unsupervised learning, we'll split the data and evaluate our predictions as follows.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data splitting \n",
    "\n",
    "- We split the ratings into train and validation sets. \n",
    "- **It's easier to split the ratings data instead of splitting the utility matrix.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ratings.copy()\n",
    "y = ratings[user_key]\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we will create utility matrices for train and validation splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "train_mat = create_Y_from_ratings(X_train, N, M, user_mapper, item_mapper)\n",
    "valid_mat = create_Y_from_ratings(X_valid, N, M, user_mapper, item_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mat.shape, valid_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that both matrices have the **same shape** (same number of users, same number of products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `train_mat` has only ratings from the train set and `valid_mat` has only ratings from the valid set.\n",
    "- During training we assume that we do not have access to some of the available ratings. We predict these ratings and evaluate them against ratings in the validation set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Questions for you\n",
    "\n",
    "- How do train and validation utility matrices differ? \n",
    "- Why are utility matrices for train and validation sets are of the same shape?\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Answer:** ???\n",
    "\n",
    "<!-- - The training matrix `train_mat` is of shape N by M but only has ratings from `X_train` and all other ratings missing.  -->\n",
    "<!-- - The validation matrix `valid_mat` is also of shape N by M but it only has ratings `X_valid` and all other ratings missing.  -->\n",
    "<!-- - They have the same shape because both have the same number of users and items; that's how we have constructed them.  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluation\n",
    "\n",
    "- Now that we have train and validation sets, how do we evaluate our predictions?\n",
    "- You can calculate the **error between actual ratings and predicted ratings** with metrics of your choice. \n",
    "    - Most common ones are MSE or RMSE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The `error` function below calculates RMSE and `evaluate` function prints train and validation RMSE.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(X1, X2):\n",
    "    \"\"\"\n",
    "    Returns the root mean squared error.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.nanmean((X1 - X2) ** 2))\n",
    "\n",
    "\n",
    "def evaluate(pred_X, train_X, valid_X, model_name=\"Global average\"):\n",
    "    print(\"%s train RMSE: %0.2f\" % (model_name, error(pred_X, train_X)))\n",
    "    print(\"%s valid RMSE: %0.2f\" % (model_name, error(pred_X, valid_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Baselines\n",
    "\n",
    "Let's first try some simple approaches to predict missing entries. \n",
    "\n",
    "1. Global average baseline\n",
    "2. [$k$-Nearest Neighbours imputation](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Global average baseline\n",
    "\n",
    "- Let's examine RMSE of the global average baseline. \n",
    "- In this baseline we predict everything as the global average rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the arithmetic mean along the specified axis, ignoring NaNs and ignoring axis\n",
    "avg = np.nanmean(train_mat)\n",
    "\n",
    "# predict everything as average\n",
    "pred_g = np.zeros(train_mat.shape) + avg\n",
    "\n",
    "pd.DataFrame(pred_g).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(pred_g, train_mat, valid_mat, model_name=\"Global average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "We can improve a little and calculate Average per product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = np.nanmean(train_mat, axis=0)\n",
    "pred_g = np.zeros(train_mat.shape) + avg\n",
    "pd.DataFrame(pred_g).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(pred_g, train_mat, valid_mat, model_name=\"Global average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [$k$-nearest neighbours imputation](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html)\n",
    "\n",
    "- Can we try $k$-nearest neighbours type imputation? \n",
    "- Impute missing values using the mean value from **$k$ nearest neighbours found in the training set**. \n",
    "- Calculate distances between examples using features where neither value is missing. \n",
    "\n",
    "<!-- ![](../img/utility_matrix.png) -->\n",
    "\n",
    "<img src=\"../img/utility_matrix.png\" alt=\"\" height=\"900\" width=\"900\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNNImputer:\n",
    "\n",
    "> Each sampleâ€™s missing values are imputed using the mean value from n_neighbors nearest neighbors found in the training set.   \n",
    "> **Two samples are close if the features that neither is missing are close.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "- This is similar to **\"User-based Collaborative Filterin\"** which we will shortly discuss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=10)\n",
    "train_mat_imp = imputer.fit_transform(train_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(train_mat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(train_mat_imp, train_mat, valid_mat, model_name=\"KNN imputer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br><br>\n",
    "\n",
    "Alternative Approaches:\n",
    "- You can also use [nearest neighbors](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html) module of SkLearn\n",
    "- We can look at nearest neighbours of a query items (here, jokes) instead of the users \n",
    "  - In this approach, columns are items, and users are features for jokes, and we'll have to find nearest neighbours of columns vectors (as opposed to the previous approach where we found nearest neighbors for row vectors) \n",
    "  - In other words, we apply KNN on the transpose of the original matrix\n",
    "  - This is similar to **\"Item-based Collaborative Filterin\"** which we will shortly discuss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### (Optional) $k$-nearest neighbours on a query joke\n",
    "- Let's transpose the matrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "item_user_mat = train_mat_imp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes_df = pd.read_csv(\"../data/jester_items.csv\")\n",
    "jokes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "id_joke_map = dict(zip(jokes_df.jokeId, jokes_df.jokeText))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "def get_topk_recommendations(X, query_ind=0, metric=\"cosine\", k=5):\n",
    "    query_idx = item_inverse_mapper[query_ind]\n",
    "    model = NearestNeighbors(n_neighbors=k, metric=\"cosine\")\n",
    "    model.fit(X)\n",
    "    neigh_ind = model.kneighbors([X[query_ind]], k, return_distance=False).flatten()\n",
    "    neigh_ind = np.delete(neigh_ind, np.where(query_ind == query_ind))\n",
    "    recs = [id_joke_map[item_inverse_mapper[i]] for i in neigh_ind]\n",
    "    print(\"Query joke: \", id_joke_map[query_idx])\n",
    "\n",
    "    return pd.DataFrame(data=recs, columns=[\"top recommendations\"])\n",
    "\n",
    "\n",
    "get_topk_recommendations(item_user_mat, query_ind=8, metric=\"cosine\", k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Question**\n",
    "- Instead of imputation, what would be the consequences if we replace `nan` with zeros so that we can calculate distances between vectors? \n",
    "\n",
    "<br><br>\n",
    "**Answer**???\n",
    "\n",
    "<!-- It's not a good idea replace ratings with 0, because 0 can be an actual rating value in our case.  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What to do with predictions? \n",
    "\n",
    "Once you have predictions, we can \n",
    "- **sort them based on ratings** and \n",
    "- **recommend items with highest ratings** to users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Break (5 min)\n",
    "\n",
    "![](../img/eva-coffee.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Collaborative filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Collaborative filtering \n",
    "- One of the most popular approach for recommendation systems. \n",
    "- Approach used by the winning entry (and most of the entries) in the Netflix competition. \n",
    "- An **unsupervised** approach\n",
    "    - Only uses the user-item interactions given in the ratings matrix. \n",
    "- **Intuition**\n",
    "    - We may have **similar users** and **similar items** which can help us predict missing entries. \n",
    "    - Leverage social information to provide recommendations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Problem \n",
    "\n",
    "- Given a utility matrix with many missing entries, how can we predict missing ratings?  \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "? & ? & \\checkmark  & ? & \\checkmark\\\\\n",
    "\\checkmark & ? & ?  & ? & ?\\\\\n",
    "? & \\checkmark & \\checkmark  & ? & \\checkmark\\\\\n",
    "? & ? & ?  & ? & ?\\\\\n",
    "? & ? & ? & \\checkmark & ?\\\\\n",
    "? & \\checkmark & \\checkmark  & ? & \\checkmark\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "> Note: rating prediction $\\neq$ Classification or regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification or regression\n",
    "\n",
    "- We have $X$ and targets for some rows in $X$. \n",
    "- We want to predict the target column.  \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "\\checkmark & \\checkmark & \\checkmark  & \\checkmark & \\checkmark\\\\\n",
    "\\checkmark & \\checkmark & \\checkmark  & \\checkmark & \\checkmark\\\\\n",
    "\\checkmark & \\checkmark & \\checkmark  & \\checkmark & \\checkmark\\\\\n",
    "\\checkmark & \\checkmark & \\checkmark  & \\checkmark & ?\\\\\n",
    "\\checkmark & \\checkmark & \\checkmark  & \\checkmark & ?\\\\\n",
    "\\checkmark & \\checkmark & \\checkmark  & \\checkmark & ?\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Rating prediction \n",
    "\n",
    "- Ratings data has many missing values in the utility matrix. There is no special target column. We want to predict the missing entries in the matrix. \n",
    "- Since our goal is to **predict** ratings, usually the utility matrix is referred to as $Y$ matrix. \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "? & ? & \\checkmark  & ? & \\checkmark\\\\\n",
    "\\checkmark & ? & ?  & ? & ?\\\\\n",
    "? & \\checkmark & \\checkmark  & ? & \\checkmark\\\\\n",
    "? & ? & ?  & ? & ?\\\\\n",
    "? & ? & ? & \\checkmark & ?\\\\\n",
    "? & \\checkmark & \\checkmark  & ? & \\checkmark\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **User-based Collaborative Filtering:** find similarities between users\n",
    "- **Item-based Collaborative Filtering:** find similarities between items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We don't have sufficient background to understand how collaborative filtering works under-the-hood.\n",
    "- Let's look at an example to understand this at a high level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_ratings = pd.read_csv(\"../data/toy-movie-ratings.csv\")\n",
    "toy_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_toy = len(np.unique(toy_ratings[\"user_id\"]))\n",
    "M_toy = len(np.unique(toy_ratings[\"movie_id\"]))\n",
    "print(\"Number of users (N)                : %d\" % N_toy)\n",
    "print(\"Number of movies (M)               : %d\" % M_toy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapper_toy = dict(zip(np.unique(toy_ratings[\"user_id\"]), list(range(N_toy))))\n",
    "item_mapper_toy = dict(zip(np.unique(toy_ratings[\"movie_id\"]), list(range(M_toy))))\n",
    "user_inverse_mapper_toy = dict(\n",
    "    zip(list(range(N_toy)), np.unique(toy_ratings[\"user_id\"]))\n",
    ")\n",
    "item_inverse_mapper_toy = dict(\n",
    "    zip(list(range(M_toy)), np.unique(toy_ratings[\"movie_id\"]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_toy = create_Y_from_ratings(\n",
    "    toy_ratings, N_toy, M_toy, user_mapper_toy, item_mapper_toy, user_key=\"user_id\", item_key=\"movie_id\"\n",
    ")\n",
    "utility_mat_toy = pd.DataFrame(\n",
    "    Y_toy, columns=item_mapper_toy.keys(), index=user_mapper_toy.keys()\n",
    ")\n",
    "utility_mat_toy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this toy example, we see clear groups of movies and users.\n",
    "    - For movies: Children movies and documentaries \n",
    "    - For users: Children movie lovers and documentary lovers  \n",
    "- There are some unsupervised models which identify such latent features. \n",
    "- I'll show you how to use a package which implements this popular algorithm for collaborative filtering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Rating prediction using the surprise package\n",
    "\n",
    "- We'll be using a package called [Surprise](https://surprise.readthedocs.io/en/stable/index.html). \n",
    "  - https://github.com/NicolasHug/Surprise\n",
    "- The collaborative filtering algorithm we use in this package is called `SVD` (Singular Value Decomposition). \n",
    "\n",
    "```\n",
    "pip install scikit-surprise\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "An even more comprehensive library and reference for other libraries is the Recommenders by Microsoft:\n",
    "- https://github.com/microsoft/recommenders    \n",
    "\n",
    "Try it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "**(Optional)**\n",
    "\n",
    "**What is Singular Value Decomposition (SVD)?**\n",
    "\n",
    "- It's a factorization approach for matrices. \n",
    "- It is one of the most general purposes linear algebra tools\n",
    "- Used for dimensionality reduction (similar to PCA)\n",
    "  - It reduces the data into its **main correlations**\n",
    "- It is a data driven generalization of the Fast Fourier Transform (FFT)\n",
    "  - It finds the tailored transformation that fits best for our data (as opposed to FFT which uses sine and cosines which may not be the best fit)\n",
    "\n",
    "\n",
    "Best tutorial I've found out there on SVD is this 4-session mini-series (!):\n",
    "- https://www.youtube.com/watch?v=gXbThCXjZFM\n",
    "- https://www.youtube.com/watch?v=nbBvuuNVfco\n",
    "- https://www.youtube.com/watch?v=xy3QyyhiuY4\n",
    "- https://www.youtube.com/watch?v=WmDnaoY2Ivs\n",
    "\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative filtering with SVD belongs to the family of **\"Matrix Factorization-based Collaborative Filtering\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's try it out on our Jester dataset utility matrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise\n",
    "from surprise import SVD, Dataset, Reader, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader()\n",
    "data = Dataset.load_from_df(ratings, reader)  # Load the data\n",
    "trainset, validset = surprise.model_selection.train_test_split(\n",
    "    data, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "svd_alg = SVD(n_factors=k, random_state=42)\n",
    "svd_alg.fit(trainset)\n",
    "\n",
    "svd_preds = svd_alg.test(validset)\n",
    "accuracy.rmse(svd_preds, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Improvement but not a big improvement over the global baseline (RMSE=5.77). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions for a single user and a single item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_alg.predict(uid=1825, iid=49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "Surprise comes with many other collaborative filtering and matrix factorization algorithms. \n",
    "\n",
    "For example,  `KNNBasic` (https://surprise.readthedocs.io/en/stable/knn_inspired.html#surprise.prediction_algorithms.knns.KNNBasic):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "from surprise import KNNBasic\n",
    "algo = KNNBasic()\n",
    "algo.fit(trainset)\n",
    "\n",
    "knn_preds = algo.test(validset)\n",
    "accuracy.rmse(knn_preds, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cross-validation for recommender systems\n",
    "\n",
    "- We can also carry out cross-validation and grid search with this package. \n",
    "- Let's look at an example of cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "pd.DataFrame(cross_validate(algo, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "**[Study on your own]**\n",
    "\n",
    "#### Other built-in datasets shipped with the Surprise library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Jester dataset is available as one of the built-in datasets in this package and you can load it as follows and run cross-validation as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_builtin(\"jester\")\n",
    "\n",
    "pd.DataFrame(cross_validate(algo, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Study on your own]**\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-based filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is content-based filtering? \n",
    "\n",
    "Going back here: https://help.netflix.com/en/node/100639\n",
    "\n",
    "- Supervised machine learning approach\n",
    "- In collaborative filtering we assumed that we only have ratings data. \n",
    "- Usually there is some information on items and users available. \n",
    "- Examples\n",
    "    - Netflix can describe movies as action, romance, comedy, documentaries. \n",
    "    - Amazon could describe books according to topics: math, languages, history. \n",
    "    - Tinder could describe people according to age, location, employment.\n",
    "- Can we use this information to predict ratings in the utility matrix?   \n",
    "    - Yes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Toy example: Movie recommendation\n",
    "\n",
    "- Let's consider movie recommendation problem with the following toy data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ratings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "toy_ratings = pd.read_csv(\"../data/toy_ratings.csv\")\n",
    "toy_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(np.unique(toy_ratings[\"user_id\"]))\n",
    "M = len(np.unique(toy_ratings[\"movie_id\"]))\n",
    "print(\"Number of users (N)                : %d\" % N)\n",
    "print(\"Number of movies (M)               : %d\" % M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "user_key = \"user_id\"\n",
    "item_key = \"movie_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapper = dict(zip(np.unique(toy_ratings[user_key]), list(range(N))))\n",
    "item_mapper = dict(zip(np.unique(toy_ratings[item_key]), list(range(M))))\n",
    "user_inverse_mapper = dict(zip(list(range(N)), np.unique(toy_ratings[user_key])))\n",
    "item_inverse_mapper = dict(zip(list(range(M)), np.unique(toy_ratings[item_key])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Utility matrix\n",
    "\n",
    "Let's create a dense utility matrix for our toy dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def create_Y_from_ratings(data, N, M):\n",
    "    Y = np.zeros((N, M))\n",
    "    Y.fill(np.nan)\n",
    "    for index, val in data.iterrows():\n",
    "        n = user_mapper[val[user_key]]\n",
    "        m = item_mapper[val[item_key]]\n",
    "        Y[n, m] = val[\"rating\"]\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Utility matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Y = create_Y_from_ratings(toy_ratings, N, M)\n",
    "utility_mat = pd.DataFrame(Y, columns=item_mapper.keys(), index=user_mapper.keys())\n",
    "utility_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = np.nanmean(Y)\n",
    "avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**: Predict missing entries in the utility matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise\n",
    "from surprise import SVD, Dataset, Reader, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's predict ratings with collaborative filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader()\n",
    "data = Dataset.load_from_df(toy_ratings, reader)  # Load the data\n",
    "\n",
    "trainset, validset = surprise.model_selection.train_test_split(\n",
    "    data, test_size=0.01, random_state=42\n",
    ")  # Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "algo = SVD(n_factors=k, random_state=42)\n",
    "algo.fit(trainset)\n",
    "preds = algo.test(trainset.build_testset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Movie features\n",
    "\n",
    "- Suppose we also have movie features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_feats_df = pd.read_csv(\"../data/toy_movie_feats.csv\", index_col=0)\n",
    "movie_feats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = movie_feats_df.to_numpy()\n",
    "Z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How can we use these features to predict missing ratings? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Overall idea\n",
    "\n",
    "- Using the ratings data and movie features, we'll build **profiles for different users**. \n",
    "- Let's consider an example user **Pat**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pat's ratings\n",
    "\n",
    "- We don't know anything about Pat but we know her ratings to movies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "utility_mat.loc[\"Pat\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We also know about movies and their features. \n",
    "- If Pat gave a high rating to _Lion King_, it means that she liked the features of the movie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_feats_df.loc[\"Lion King\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Supervised approach to rating prediction \n",
    "\n",
    "- We treat ratings prediction problem as a set of regression problems. \n",
    "- Given movie information, **we create user profile for each user**.\n",
    "- Build regression model for each user and learn regression weights for each user. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We build a **profile** for users based on \n",
    "    - the movies they have watched\n",
    "    - their rating for the movies\n",
    "    - the features of the movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Supervised approach to rating prediction \n",
    "\n",
    "For each user $i$ create a user profile as follows. \n",
    "\n",
    "- Consider all movies rated by $i$ and create `X` and `y` for the user: \n",
    "    - Each row in `X` contains the **movie features** of movie $j$ **rated by $i$**. \n",
    "    - Each value in `y` is the corresponding rating given to the movie $j$ **by user $i$**. \n",
    "- Fit a regression model using `X` and `y`. \n",
    "- Apply the model to predict ratings for new items! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's build user profiles \n",
    "\n",
    "- Build `X` and `y` for all users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def get_lr_data_per_user(ratings_df, d):\n",
    "    lr_y = defaultdict(list)\n",
    "    lr_X = defaultdict(list)\n",
    "    lr_items = defaultdict(list)\n",
    "\n",
    "    for index, val in ratings_df.iterrows():\n",
    "        n = user_mapper[val[user_key]]\n",
    "        m = item_mapper[val[item_key]]\n",
    "        lr_X[n].append(Z[m])\n",
    "        lr_y[n].append(val[\"rating\"])\n",
    "        lr_items[n].append(m)\n",
    "\n",
    "    for n in lr_X:\n",
    "        lr_X[n] = np.array(lr_X[n])\n",
    "        lr_y[n] = np.array(lr_y[n])\n",
    "\n",
    "    return lr_X, lr_y, lr_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "d = movie_feats_df.shape[1]\n",
    "X_train_usr, y_train_usr, rated_items = get_lr_data_per_user(toy_ratings, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What's the shape of each `X` and `y`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_usr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_usr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Examine user profiles \n",
    "\n",
    "- Let's examine some user profiles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_user_profile(user_name):\n",
    "    X = X_train_usr[user_mapper[user_name]]\n",
    "    y = y_train_usr[user_mapper[user_name]]\n",
    "    items = rated_items[user_mapper[user_name]]\n",
    "    movie_names = [item_inverse_mapper[item] for item in items]\n",
    "    print(\"Profile for user: \", user_name)\n",
    "    profile_df = pd.DataFrame(X, columns=movie_feats_df.columns, index=movie_names)\n",
    "    profile_df[\"ratings\"] = y\n",
    "    return profile_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pat's profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "get_user_profile(\"Pat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pat seems to like Children's movies and movies with Comedy. \n",
    "- Seems like she's not so much into romantic movies.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Eva's profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "get_user_profile(\"Eva\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eva hasn't rated many movies. There are not many rows. \n",
    "- Eva seems to like documentaries and action movies. \n",
    "- Seems like she's not so much into romantic movies.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regression models for users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can train **a Regression model for ratings of each user**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "def train_for_usr(user_name, model=Ridge()):\n",
    "    X = X_train_usr[user_mapper[user_name]]\n",
    "    y = y_train_usr[user_mapper[user_name]]\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_for_usr(model, movie_names):\n",
    "    feat_vecs = movie_feats_df.loc[movie_names].values\n",
    "    preds = model.predict(feat_vecs)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regression model for Pat \n",
    "\n",
    "- What are the regression weights learned for Pat? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_name = \"Pat\"\n",
    "pat_model = train_for_usr(user_name)\n",
    "col = \"Coefficients for %s\" % user_name\n",
    "pd.DataFrame(pat_model.coef_, index=movie_feats_df.columns, columns=[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predictions for Pat\n",
    "- How would Pat rate some movies she hasn't seen? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_to_pred = [\"Roman Holidays\", \"Malcolm x\"]\n",
    "pred_df = movie_feats_df.loc[movies_to_pred]\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_name = \"Pat\"\n",
    "preds = predict_for_usr(pat_model, movies_to_pred)\n",
    "pred_df[user_name + \"'s predicted ratings\"] = preds\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regression model for Eva \n",
    "\n",
    "- What are the regression weights learned for Eva? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_name = \"Eva\"\n",
    "eva_model = train_for_usr(user_name)\n",
    "col = \"Coefficients for %s\" % user_name\n",
    "pd.DataFrame(eva_model.coef_, index=movie_feats_df.columns, columns=[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predictions for Eva\n",
    "\n",
    "- What are the predicted ratings for Eva for a list of movies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_name = \"Eva\"\n",
    "preds = predict_for_usr(eva_model, movies_to_pred)\n",
    "pred_df[user_name + \"'s predicted ratings\"] = preds\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completing the utility matrix with content-based filtering\n",
    "\n",
    "Here is the original utility matrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using predictions per user, we can fill in missing entries in the utility matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "models = dict()\n",
    "pred_lin_reg = np.zeros((N, M))\n",
    "\n",
    "# features of each movie\n",
    "Z = movie_feats_df.to_numpy()\n",
    "\n",
    "# iterate over all users\n",
    "for n in range(N):\n",
    "    \n",
    "    # train a model for each user\n",
    "    models[n] = Ridge()\n",
    "    models[n].fit(X_train_usr[n], y_train_usr[n])\n",
    "    \n",
    "    # predict \n",
    "    pred_lin_reg[n] = models[n].predict(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pred_lin_reg, columns=item_mapper.keys(), index=user_mapper.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### More comments on content-based filtering\n",
    "\n",
    "- The feature matrix for movies can contain different types of features.\n",
    "    - Example: Plot of the movie (text features), actors (categorical features), year of the movie, budget and revenue of the movie (numerical features). \n",
    "    - You'll apply our usual preprocessing techniques to these features. \n",
    "- If you have enough data, you could also carry out hyperparameter tuning with cross-validation for each model.\n",
    "- Finally, although we have been talking about linear models above, **you can use any regression model of your choice**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Advantages of content-based filtering \n",
    "\n",
    "- We don't need many users to provide ratings for an item. \n",
    "- **Each user is modeled separately, so you might be able to capture personalization**. \n",
    "- Since you can obtain the features of the items, you can immediately recommend new items. \n",
    "    - This would not have been possible with collaborative filtering (**what to do in collaboration filtering cold-start when a new item just added?**)\n",
    "- Recommendations are interpretable.\n",
    "    - You can explain to the user why you are recommending an item because you have learned weights. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Disadvantages of content-based filtering \n",
    "\n",
    "- Feature acquisition and feature engineering\n",
    "    - What features should we use to explain the difference in ratings? \n",
    "    - Obtaining those features for each item might be very expensive. \n",
    "- Less diversity: hardly recommend an item outside the user's profile. \n",
    "- **Cold start: When a new user shows up, you don't have any information about them.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid filtering\n",
    "\n",
    "- Combining advantages of collaborative filtering and content-based filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Final comments and summary <a name=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Formulating the problem of recommender systems \n",
    "\n",
    "- We are given ratings data. \n",
    "- We use this data to create **utility matrix** which encodes interactions between users and items. \n",
    "- The utility matrix has many missing entries. \n",
    "- We defined recommendation systems problem as **matrix completion problem**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What did we cover? \n",
    "\n",
    "- There is a big world of recommendation systems out there. We talked about some basic traditional approaches to recommender systems. \n",
    "    - collaborative filtering \n",
    "    - content-based filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to know more advanced approaches to recommender systems, watch this 4-hour summer school tutorial by Xavier Amatriain, Research/Engineering Director @ Netflix.  \n",
    "\n",
    "- [Part1](https://www.youtube.com/watch?v=bLhq63ygoU8)\n",
    "- [Part2](https://www.youtube.com/watch?v=mRToFXlNBpQ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluation \n",
    "\n",
    "- We split the data similar to supervised systems. \n",
    "- We evaluate recommendation systems using traditional regression metrics such as MSE or RMSE. \n",
    "- But **real evaluation of recommender system can be very tricky because there is no ground truth**. \n",
    "- We have been using RMSE due to the lack of a better measure.  \n",
    "- What we actually want to measure is the **interest that our user has in the recommended items**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Beyond error rate in recommendation systems \n",
    "\n",
    "- If a system gives the best RMSE it doesn't necessarily mean that it's going to give best recommendations. \n",
    "- In recommendation systems we do not have ground truth.\n",
    "- Just training your model and evaluating it offline is not ideal. \n",
    "- Other aspects such as simplicity and **interpretation** are equally (if not more) important than best validation error. \n",
    "- Winning system of Netflix Challenge was never adopted.\n",
    "    - **Big mess of ensembles was not really maintainable**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Other issues important in recommender systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are these good recommendations? \n",
    "\n",
    "You are looking for water shoes and at the moment you are looking at [VIFUUR Water Sports Shoes](https://www.amazon.ca/VIFUUR-Barefoot-Quick-Dry-Blue-38-39/dp/B0753DL15Y), are these good recommendations? \n",
    "\n",
    "![](../img/reco-diversity.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose you've recently bought VIFUUR Water Sports Shoes and rated them highly. Are these good recommendations now? \n",
    "- Not really. Even though you really liked them you don't need them anymore. You want some non-Water Sports Shoes recommendations.\n",
    "- **Diversity** is about how different are the recommendations. \n",
    "    - Another example: Even if you really really like Star Wars, you might want non-Star-Wars suggestions.    \n",
    "- **We need a balance between Exploration and Exploitation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "**We need a balance between Exploration and Exploitation**  \n",
    "What are they?\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are these good recommendations? \n",
    "\n",
    "![](../img/freshness.png)\n",
    "\n",
    "- Some of these books don't have many ratings but it might be a good idea to recommend \"fresh\" things. \n",
    "- **Freshness**: people tend to get more excited about new/surprising things.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- But again you need a balance here. What would happen if you keep surprising the user all the time? \n",
    "- There might be **trust** issues. \n",
    "- Another aspect of trust is **explaining** your recommendation, i.e., telling the user why you made a recommendation. This gives the user an opportunity to understand why your recommendations could be interesting to them.   \n",
    "  - **We are recommeding you THIS item because you liked ANOTHER item**\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Persistence**: how long should recommendations last?\n",
    "- If you keep not clicking on a recommendation, should it remain a recommendation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Social recommendation**: what did your friends watch?\n",
    "- Many recommenders\tare\tnow\tconnected to social\tnetworks.\n",
    "- \"Login using you Facebook\taccount\".\n",
    "- Often, people\tlike similar movies\tto their friends.\n",
    "- If we get a new user, then recommendations are based on friend's preferences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Types of data \n",
    "\n",
    "- Explicit data: ratings, thumbs up, etc. \n",
    "- Implicit data: collected from the users' behaviour (e.g., mouse clicks, purchases, time spent doing something)\n",
    "- Trust implicit data that costs something, like time or even money. \n",
    "    - this makes it harder to fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some thoughts on recommendation systems  \n",
    "- Be mindful of the consequences of recommendation systems. \n",
    "    - Recommendation systems can have terrible consequences. \n",
    "- **All for-profit companies (small tech / big tech)**, which extensively use recommendation systems, are **profit-driven**\n",
    "  - They make decisions to infinitely increase profit margins of the company\n",
    "  - All actions of a company has roots in profit\n",
    "  - Product design in a for-profit company, including the recommendation systems, are no exception; they are intended to maximize user attention/engagement\n",
    "- There are tons of news and research articles on serious consequences of recommendation systems.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some thoughts on recommendation systems  \n",
    "\n",
    "- Some weird stories which got media attention.   \n",
    "[How Target Figured Out A Teen Girl Was Pregnant Before Her Father Did](https://www.forbes.com/sites/kashmirhill/2012/02/16/how-target-figured-out-a-teen-girl-was-pregnant-before-her-father-did/?sh=3171af136668)\n",
    "- More serious consequences are in political contexts. \n",
    "    - [Facebook Admits It Was Used to Incite Violence in Myanmar](https://www.nytimes.com/2018/11/06/technology/myanmar-facebook.html)\n",
    "    - [YouTube Extremism and the Long Tail](https://www.theatlantic.com/politics/archive/2018/03/youtube-extremism-and-the-long-tail/555350/)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### My advice\n",
    "\n",
    "- Ask hard and uncomfortable questions from **yourself (and from your employer where possible)** before implementing and deploying such systems.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Resources \n",
    "\n",
    "- [Collaborative filtering for recommendation systems in Python, by N. Hug](https://www.youtube.com/watch?v=z0dx-YckFko)\n",
    "- [An interesting talk: The paradox of choice](https://www.ted.com/talks/barry_schwartz_the_paradox_of_choice)\n",
    "- [How Netflixâ€™s Recommendations System Works](https://help.netflix.com/en/node/100639)\n",
    "- [Hands on Recommendation Systems with Python](https://learning.oreilly.com/library/view/hands-on-recommendation-systems/9781788993753/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
